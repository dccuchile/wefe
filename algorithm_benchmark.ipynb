{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msxVB45IDgnY"
      },
      "source": [
        "# Benchmark - WEFE, Fair Embedding Engine and Responsibly.AI\n",
        "\n",
        "To the best of our knowledge, we are aware of only three Python libraries that implement bias measurement and mitigation methods: Fair Embedding Engine (FEE) and Responsibly.\n",
        "\n",
        "According to its authors, Fair Embedding Engine () is defined as \"A Library for Analyzing and Mitigating Gender Bias in Word Embeddings\", while Responsibly () is defined as \"Toolkit for Auditing and Mitigating Bias and Fairness of Machine Learning Systems.\"\n",
        "\n",
        "The FEE and Responsibly documentation can be found at the following links respectively: \n",
        "- https://github.com/FEE-Fair-Embedding-Engine/FEE\n",
        "- https://docs.responsibly.ai/\n",
        "\n",
        "The following document shows a comparison in various areas between these libraries with respect to WEFE.\n",
        "\n",
        "The points to be evaluated are:\n",
        "    \n",
        "1. Ease of installation\n",
        "2. Quality of the package and documentation.\n",
        "3. Ease of loading models\n",
        "4. Ease of running bias measurements. \n",
        "5. Performance in execution times.   \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-CdwX9aDgnk"
      },
      "source": [
        "## 0. Metrics Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZk0lFZsDgnl"
      },
      "source": [
        "## 1. Ease of installation\n",
        "\n",
        "This comparison aims to evaluate how easy it is to install the library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUYPAQ-ZDgnm"
      },
      "source": [
        "### WEFE\n",
        "\n",
        "According to the documentation, WEFE is available for installation using the Python Package Index (via pip) as well as via conda.\n",
        "\n",
        "\n",
        "```bash\n",
        "pip install --upgrade wefe\n",
        "# or\n",
        "conda install -c pbadilla wefe\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Glb9kZ8oDgno"
      },
      "source": [
        "### Fair Embedding Engine\n",
        "\n",
        "In the case of FEE, neither the documentation nor the repository indicates how to install the package. Therefore, the easiest thing to do in this case is to clone the repository and then install the requirements manually."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QshcyhwNDgnp"
      },
      "source": [
        "1. Clone the repo\n",
        "```bash\n",
        "$ git clone https://github.com/FEE-Fair-Embedding-Engine/FEE\n",
        "```\n",
        "\n",
        "2. Install the requirements.\n",
        "```bash\n",
        "$ pip install -r FEE/requirements.txt\n",
        "$ pip install sympy\n",
        "$ pip install -U gensim==3.8.3\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rM4fFeEDDgns"
      },
      "source": [
        "### Responsibly\n",
        "\n",
        "According to its documentation, responsibly is also hosted in the Python Package Index so it can be installed using pip."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaOcz5TADgnv"
      },
      "source": [
        "```bash\n",
        "$ pip install responsibly\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oiJpM7jkDgnx"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "Both WEFE and responsibly are easy to install, which lowers the initial barriers to entry. FEE, on the other hand, requires more knowledge of Python to be able to use it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mlLwXlUDgny"
      },
      "source": [
        "## 2. Quality of the package and documentation\n",
        "\n",
        "This benchmark seeks to compare the quality of the documentation as well as the quality and best practices of the code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjnPFMjXDgnz"
      },
      "source": [
        "### WEFE\n",
        "\n",
        "WEFE has a complete documentation page, which explains in detail the use of the package: an about with the motivation and objectives of the project, quick start showing how to install the library, multiple user manuals to measure and mitigate bias, detailed API of the implemented methods, theoretical manuals and finally implementations of previous case studies.\n",
        "\n",
        "In addition, most of the code is tested and was developed using continuous integration mechanisms (through a linter and testing in Github Actions) that keep it with a good code quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svr-ZVOLDgn0"
      },
      "source": [
        "### Fair Embedding Engine"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4HV8oj1Dgn1"
      },
      "source": [
        "FEE has a documentation, which covers only the basic aspects of the API plus a flowchart showing the main concepts of the library.\n",
        "The documentation does not contain user guides, code examples or theoretical information about the implemented methods.\n",
        "\n",
        "On the other hand, no tests, linters or continuous code integration mechanisms could be identified."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-3AIIcXDgn3"
      },
      "source": [
        "### Responsibly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DC1hiQ2rDgn4"
      },
      "source": [
        "Responsibly has also a complete documentation page, which explains the use of the package: an index with the main project information and a quick start showing how to install the library, demos that act as user manuals, and a detailed API of the implemented methods.\n",
        "\n",
        "In addition, most of the code is tested and was developed using continuous integration mechanisms (through a linter and testing in Github Actions) that keep it with a good code quality.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCgd1XcWDgn5"
      },
      "source": [
        "### Conclusion\n",
        "\n",
        "In terms of documentation, WEFE contains much more detailed documentation than the other libraries with more extensive manuals and replications of previous case studies. \n",
        "Responsibly has sufficient documentation to execute its main functionalities without major problems, however, it is not exhaustive.\n",
        "FEE, on the other hand, only has API documentation, which makes it insufficient for new users to use it directly.\n",
        "\n",
        "With respect to software quality, both WEFE and Responsibly comply with best practices. \n",
        "FEE contains neither testing nor mechanisms to control code quality."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5eZwbpBDgn6"
      },
      "source": [
        "## 3. Ease of loading models\n",
        "\n",
        "This comparison looks at how easy it is to load a Word Embedding model.\n",
        "In this benchmark, two tests will be compared: loading a model from gensim API (`glove-twitter-25`) and loading a model from a binary file (`word2vec`).\n",
        "\n",
        "For the second test, you need to download the original word2vec model, which can be downloaded using the following code:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t2IQgI7Dgn_"
      },
      "source": [
        "### WEFE\n",
        "\n",
        "In WEFE, models are simply wrappers of Gensim models. This implies that the model reading process (either loaded by the API or by a file) is handled by the Gensim loaders, while the class that generates the objects that allow access to the embeddings is managed by WEFE.\n",
        "\n",
        "The following code can be used for the loading of the glove model from the gensim API:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xf6_a2IvDgn7",
        "outputId": "baf1ee9d-c399-4638-aa5d-cb2346420829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-01-17 17:11:56--  https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/word2vec-google-news-300.gz\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/106859079/44040504-c5dc-11e7-8524-2dee13a5133a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230117T171156Z&X-Amz-Expires=300&X-Amz-Signature=adf4519590f2f57a5103455752d30ec814e1be054fc1670668fc0af41380f99c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106859079&response-content-disposition=attachment%3B%20filename%3Dword2vec-google-news-300.gz&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-01-17 17:11:56--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/106859079/44040504-c5dc-11e7-8524-2dee13a5133a?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230117%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230117T171156Z&X-Amz-Expires=300&X-Amz-Signature=adf4519590f2f57a5103455752d30ec814e1be054fc1670668fc0af41380f99c&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=106859079&response-content-disposition=attachment%3B%20filename%3Dword2vec-google-news-300.gz&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1743563840 (1.6G) [application/octet-stream]\n",
            "Saving to: ‘word2vec-google-news-300.gz’\n",
            "\n",
            "word2vec-google-new 100%[===================>]   1.62G   121MB/s    in 12s     \n",
            "\n",
            "2023-01-17 17:12:09 (133 MB/s) - ‘word2vec-google-news-300.gz’ saved [1743563840/1743563840]\n",
            "\n",
            "gzip: word2vec-google-news-300 already exists; do you wish to overwrite (y or n)? ^C\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/word2vec-google-news-300.gz\n",
        "!gzip -dv word2vec-google-news-300.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l11Jo96dDgoA"
      },
      "outputs": [],
      "source": [
        "from wefe.word_embedding_model import WordEmbeddingModel\n",
        "import gensim.downloader as api\n",
        "\n",
        "# load glove\n",
        "twitter_25 = api.load('glove-twitter-25')\n",
        "model = WordEmbeddingModel(twitter_25, 'glove twitter dim=25')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ll5lrq5hDgoB"
      },
      "source": [
        "The following code allows you to load word2vec from its original file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dZQbftrKDgoB"
      },
      "outputs": [],
      "source": [
        "from wefe.word_embedding_model import WordEmbeddingModel\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "# load word2vec\n",
        "word2vec = KeyedVectors.load_word2vec_format('word2vec-google-news-300', binary=True)\n",
        "model = WordEmbeddingModel(word2vec, 'word2vec-google-news-300')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvzcyPZpDgoD"
      },
      "source": [
        "### FEE\n",
        "\n",
        "FEE also offers direct support for loading models from the FEE API through the following code.\n",
        "In this case, the model loading is coupled to the class which then has the methods to access the embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "eJaCxhn6DgoE"
      },
      "outputs": [],
      "source": [
        "from FEE.fee.embedding.loader import WE\n",
        "\n",
        "fee_model = WE().load(ename = 'glove-twitter-25')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "mr4Kb8bVDgoF"
      },
      "outputs": [],
      "source": [
        "from FEE.fee.embedding.loader import WE\n",
        "\n",
        "fee_model = WE().load(fname = 'word2vec-google-news-300', format='bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "from gensim.models.keyedvectors import KeyedVectors\n"
      ],
      "metadata": {
        "id": "2P1gDQRSW1sI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W16TBj9DgoG"
      },
      "source": [
        "### Responsibly\n",
        "\n",
        "Responsibly has no intermediate interfaces to handle embedding models, it simply uses the gensim interface for this purpose. This can be reflected into the following script.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wqX-sdK6DgoG"
      },
      "outputs": [],
      "source": [
        "twitter_25 = api.load('glove-twitter-25')\n",
        "\n",
        "word2vec = KeyedVectors.load_word2vec_format('word2vec-google-news-300', binary=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uIbZB1-DgoH"
      },
      "source": [
        "### Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEBTK7XGDgoH"
      },
      "source": [
        "In this case, the three libraries show similar behaviors and capabilities, which does not allow us to distinguish significant differences between them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ZIXm_3DgoH"
      },
      "source": [
        "## 4. Ease of running bias measurements. \n",
        "\n",
        "This benchmark is intended to show how easy it is to run queries on the metrics that can be used. \n",
        "To keep the comparison simple, the set of words and the embeddings model will be kept fixed; only the metrics executed will be varied."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EZX8LVMLDgoH"
      },
      "outputs": [],
      "source": [
        "# words to evaluate\n",
        "\n",
        "female_terms = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
        "male_terms = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]\n",
        "\n",
        "family_terms = [\n",
        "    \"home\",\n",
        "    \"parents\",\n",
        "    \"children\",\n",
        "    \"family\",\n",
        "    \"cousins\",\n",
        "    \"marriage\",\n",
        "    \"wedding\",\n",
        "    \"relatives\",\n",
        "]\n",
        "career_terms = [\n",
        "    \"executive\",\n",
        "    \"management\",\n",
        "    \"professional\",\n",
        "    \"corporation\",\n",
        "    \"salary\",\n",
        "    \"office\",\n",
        "    \"business\",\n",
        "    \"career\",\n",
        "]\n",
        "\n",
        "# optional, only for wefe use.\n",
        "target_sets_names = [\"Female Terms\", \"Male Terms\"]\n",
        "attribute_sets_names = [\"Arts\", \"Science\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h89uMpUiDgoI"
      },
      "source": [
        "### WEFE\n",
        "\n",
        "WEFE defines a standardized framework to execute metrics: in short, it is necessary to define a query that will act as a container for the words to be tested and then, together with the model, be delivered as input to some metric.\n",
        "\n",
        "The outputs of the metrics are always dictionaries since most of them contain additional information that could eventually be useful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BrgMdNUsDgoI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2d5287d-8b24-4433-98c6-6138fa604d51"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Query: Female Terms and Male Terms wrt Arts and Science\n",
              "- Target sets: [['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter'], ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']]\n",
              "- Attribute sets:[['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives'], ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']]>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# import the modules\n",
        "from wefe.query import Query\n",
        "\n",
        "# 1. create the query\n",
        "query = Query(\n",
        "    [female_terms, male_terms],\n",
        "    [family_terms, career_terms],\n",
        "    target_sets_names,\n",
        "    attribute_sets_names,\n",
        ")\n",
        "query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcIwk9a8DgoJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35479d03-b170-4a62-d0f2-80cea42fb2b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.46343880688073114,\n",
              " 'weat': 0.46343880688073114,\n",
              " 'effect_size': 0.45076526581093423,\n",
              " 'p_value': nan}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "from wefe.metrics.WEAT import WEAT\n",
        "\n",
        "# 2. instance a WEAT metric and pass the query plus the model.\n",
        "weat = WEAT()\n",
        "result = weat.run_query(query, model)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9YPdDokDgoJ"
      },
      "source": [
        "As run query is independent of the query and the model, it can take several parameters that customize the performance of the metric. In this case, we show how to standardize the words before searching for them in the model by making them all lowercase and then removing their accents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfB1fApcDgoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f92c6cfa-f326-4428-f606-707ca11c0044"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.46343880688073114,\n",
              " 'weat': 0.46343880688073114,\n",
              " 'effect_size': 0.45076526581093423,\n",
              " 'p_value': nan}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "weat = WEAT()\n",
        "result = weat.run_query(\n",
        "    query,\n",
        "    model,\n",
        "    preprocessors=[{\"lowercase\": True, \"strip_accents\": True}],\n",
        ")\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSUZiPfpDgoK"
      },
      "source": [
        "In this case, we show how to calculate the p-value through a permutation test."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "081UJkVKDgoK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd7745de-20c6-49cf-875c-85ac74fcc76c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.46343880688073114,\n",
              " 'weat': 0.46343880688073114,\n",
              " 'effect_size': 0.45076526581093423,\n",
              " 'p_value': 0.1837816218378162}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "weat = WEAT()\n",
        "result = weat.run_query(\n",
        "    query,\n",
        "    model,\n",
        "    calculate_p_value=True,\n",
        ")\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DG6-uHvaDgoL"
      },
      "source": [
        "This interface makes it possible for us to switch very easily to similar metrics (i.e. supporting the same number of word sets). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HoINrHgvDgoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20b75059-5de4-420e-db60-7f6640a1878a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.09665597783037311,\n",
              " 'rnsb': 0.09665597783037311,\n",
              " 'negative_sentiment_probabilities': {'female': 0.563239371795448,\n",
              "  'woman': 0.30234464965107843,\n",
              "  'girl': 0.19143334905865195,\n",
              "  'sister': 0.15438537572028865,\n",
              "  'she': 0.38229504132390235,\n",
              "  'her': 0.37854574816662556,\n",
              "  'hers': 0.30166728366749673,\n",
              "  'daughter': 0.13469535205337924,\n",
              "  'male': 0.4713249668158237,\n",
              "  'man': 0.4032154496142717,\n",
              "  'boy': 0.19473458117802422,\n",
              "  'brother': 0.17832032007221466,\n",
              "  'he': 0.510376309937578,\n",
              "  'him': 0.4625630377446609,\n",
              "  'his': 0.5307538027998574,\n",
              "  'son': 0.17367200729993326},\n",
              " 'negative_sentiment_distribution': {'female': 0.1056027624821933,\n",
              "  'woman': 0.05668714195722143,\n",
              "  'girl': 0.035892182798530355,\n",
              "  'sister': 0.028945991667703896,\n",
              "  'she': 0.07167718463706767,\n",
              "  'her': 0.07097422292204784,\n",
              "  'hers': 0.056560141391103914,\n",
              "  'daughter': 0.025254273729135232,\n",
              "  'male': 0.08836956543701145,\n",
              "  'man': 0.07559958960083273,\n",
              "  'boy': 0.036511136743971634,\n",
              "  'brother': 0.0334335974175713,\n",
              "  'he': 0.09569137197044204,\n",
              "  'him': 0.08672677560213488,\n",
              "  'his': 0.09951198474447126,\n",
              "  'son': 0.03256207689856104}}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "from wefe.metrics import RNSB\n",
        "\n",
        "rnsb = RNSB()\n",
        "result = rnsb.run_query(query, model)\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2q3sjuyDgoL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f89398e-70a9-491c-f00e-192e9f19dfba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.8416415235615204,\n",
              " 'mac': 0.8416415235615204,\n",
              " 'targets_eval': {'Female Terms': {'female': {'Arts': 0.9185737599618733,\n",
              "    'Science': 0.916069650076679},\n",
              "   'woman': {'Arts': 0.752434104681015, 'Science': 0.9377805145923048},\n",
              "   'girl': {'Arts': 0.707457959651947, 'Science': 0.9867974997032434},\n",
              "   'sister': {'Arts': 0.5973392464220524, 'Science': 0.9482253392925486},\n",
              "   'she': {'Arts': 0.7872791914269328, 'Science': 0.9161583095556125},\n",
              "   'her': {'Arts': 0.7883057091385126, 'Science': 0.9237247597193345},\n",
              "   'hers': {'Arts': 0.7385367527604103, 'Science': 0.9480051446007565},\n",
              "   'daughter': {'Arts': 0.5472579970955849, 'Science': 0.9277344475267455}},\n",
              "  'Male Terms': {'male': {'Arts': 0.8735092766582966,\n",
              "    'Science': 0.9468009045813233},\n",
              "   'man': {'Arts': 0.8249392118304968, 'Science': 0.9350165261421353},\n",
              "   'boy': {'Arts': 0.7106057899072766, 'Science': 0.9879048476286698},\n",
              "   'brother': {'Arts': 0.6280269809067249, 'Science': 0.9477180293761194},\n",
              "   'he': {'Arts': 0.8693044614046812, 'Science': 0.8771287016716087},\n",
              "   'him': {'Arts': 0.8230192996561527, 'Science': 0.888683641096577},\n",
              "   'his': {'Arts': 0.8876195731572807, 'Science': 0.8920885202242061},\n",
              "   'son': {'Arts': 0.5764635019004345, 'Science': 0.9220191016211174}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from wefe.metrics import MAC\n",
        "\n",
        "rnsb = MAC()\n",
        "result = rnsb.run_query(query, model)\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToiBZTUmDgoM"
      },
      "source": [
        "### 2. Fair Embedding Engine\n",
        "\n",
        "In the case of Fair Embedding Engine, the embedding model is delivered at the time of instantiating the metric and then through the compute method its value is calculated.\n",
        "\n",
        "In this case, FEE differs somewhat from WEFE normalization by making each instance of the metric model-dependent.\n",
        "\n",
        "On the other hand, we can see that the word sets are delivered directly as star * (arbitrary number of positional arguments) parameters, which makes it difficult to understand how many and which word sets to pass. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJgFwfFwDgoM"
      },
      "outputs": [],
      "source": [
        "from FEE.fee.metrics import WEAT as FEE_WEAT\n",
        "fee_weat = FEE_WEAT(fee_model)\n",
        "\n",
        "fee_weat.compute(female_terms, male_terms, family_terms, career_terms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4pEB0wDgoO"
      },
      "source": [
        "WEAT's implementation of FEE also allows the p_value to be calculated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KflTCDE0DgoQ"
      },
      "outputs": [],
      "source": [
        "fee_weat.compute(female_terms, male_terms, family_terms, career_terms, p_val=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug7PmiAxDgoR"
      },
      "source": [
        "However, it does not contain the possibility of executing more complex actions such as preprocessing word sets.\n",
        "\n",
        "Finally, we were not able to find any other metric that was easily replaceable using the same interface (unlike with WEFE and its standardization layer)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80TkW_rDDgoS"
      },
      "source": [
        "### Responsibly"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Ease of running bias mitigation algorithms. \n",
        "\n",
        "This benchmark is intended to show how easy it is to execute bias mitigation algoritms. \n",
        "To keep the comparison simple, the set of words and the embeddings model will be kept fixed; only the algorithms executed will be varied."
      ],
      "metadata": {
        "id": "DBu9orevEsg3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wefe"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhRKRdjRiAO6",
        "outputId": "90242f22-2114-41a1-df5d-80739d313886"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wefe in /usr/local/lib/python3.8/dist-packages (0.4.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.8/dist-packages (from wefe) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from wefe) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from wefe) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from wefe) (1.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from wefe) (2.25.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from wefe) (1.3.5)\n",
            "Requirement already satisfied: semantic-version in /usr/local/lib/python3.8/dist-packages (from wefe) (2.10.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from wefe) (4.64.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.8/dist-packages (from wefe) (3.6.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.8/dist-packages (from wefe) (5.5.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.8/dist-packages (from gensim->wefe) (6.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->wefe) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->wefe) (2022.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.8/dist-packages (from plotly->wefe) (8.1.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->wefe) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->wefe) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->wefe) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->wefe) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->wefe) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->wefe) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from wefe.datasets import fetch_debiaswe\n",
        "from wefe.debias.hard_debias import HardDebias\n",
        "from wefe.utils import load_test_model"
      ],
      "metadata": {
        "id": "JQNXCYybISvQ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word sets to be used\n",
        "debiaswe_wordsets = fetch_debiaswe()\n",
        "\n",
        "definitional_pairs = debiaswe_wordsets[\"definitional_pairs\"]\n",
        "\n",
        "gender_specific = debiaswe_wordsets[\"gender_specific\"]\n",
        "\n",
        "targets = [\n",
        "    \"executive\",\n",
        "    \"management\",\n",
        "    \"professional\",\n",
        "    \"corporation\",\n",
        "    \"salary\",\n",
        "    \"office\",\n",
        "    \"business\",\n",
        "    \"career\",\n",
        "    \"home\",\n",
        "    \"parents\",\n",
        "    \"children\",\n",
        "    \"family\",\n",
        "    \"cousins\",\n",
        "    \"marriage\",\n",
        "    \"wedding\",\n",
        "    \"relatives\",\n",
        "]"
      ],
      "metadata": {
        "id": "9KF-mlEFJcZf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. WEFE"
      ],
      "metadata": {
        "id": "-flGDB1MFO4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "WEFE defines an standarize framework to execute bias mitigation algorithms based on scikit-learn's fit transform interface. \n",
        "\n",
        "WEFE allows the user to choose the word sets that will be used for the debias proccess, this way the algorithms can be used for any type of bias depending on the words provided.\n",
        "The fit methods receives parameters that are neccesary for the algorithm to function, such as definitional pairs. The transform method can receive 2 word sets: target and ignore. If target is provided the algorithms is perfomed only on those words. If it's not provided the will be perfomed over al of the words en the embedding, expcept those provided in the ignore parameter (if provided)."
      ],
      "metadata": {
        "id": "01a7gh_ecK1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wefe.debias.hard_debias import HardDebias\n",
        "\n",
        "# 1. instance Hard Debias algortihm\n",
        "hd = HardDebias(verbose=False, criterion_name=\"gender\")"
      ],
      "metadata": {
        "id": "mlzsFnWrKItO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. apply fit method and pass the model and definitional pairs.\n",
        "hd.fit(\n",
        "    model, definitional_pairs=definitional_pairs\n",
        ")\n",
        "# 3. apply transform method passing the model, target and ignore word sets resulting in the debiased model\n",
        "gender_debiased_model = hd.transform(model,  target=targets, ignore=gender_specific, copy=True)"
      ],
      "metadata": {
        "id": "XScgYULtK8ru",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c96ed768-e14f-4f08-d8d4-cbbb2ccd5658"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy argument is True. Transform will attempt to create a copy of the original model. This may fail due to lack of memory.\n",
            "Model copy created successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:00<00:00, 7653.84it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The interface makes it possible to use different algorithms in a very similar way."
      ],
      "metadata": {
        "id": "9xbwaLMYmoiP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from wefe.debias.repulsion_attraction_neutralization import (\n",
        "  RepulsionAttractionNeutralization\n",
        ")\n",
        "\n",
        "ran = RepulsionAttractionNeutralization().fit(\n",
        "    model = model,\n",
        "    definitional_pairs= definitional_pairs\n",
        "  )\n",
        "\n",
        "debiased_model = ran.transform(\n",
        "   model = model, target = targets, ignore=gender_specific, copy=True\n",
        ")"
      ],
      "metadata": {
        "id": "m4fK0I8tLqyg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14fb5d8c-857c-42a5-df35-923f8704e5ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copy argument is True. Transform will attempt to create a copyof the original model. This may fail due to lack of memory.\n",
            "Model copy created successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 16/16 [00:09<00:00,  1.63it/s]\n",
            "100%|██████████| 16/16 [00:00<00:00, 51901.67it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is possible to compare the bias in the model before and after applying the algorithms."
      ],
      "metadata": {
        "id": "czV-7GPN2twn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weat = WEAT()\n",
        "result = weat.run_query(\n",
        "    query,\n",
        "    model,\n",
        "    calculate_p_value=True,\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLKCSGK0wzeJ",
        "outputId": "0eaddd33-2326-47c4-d2fc-939c633320dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.46343880688073114,\n",
              " 'weat': 0.46343880688073114,\n",
              " 'effect_size': 0.45076526581093423,\n",
              " 'p_value': 0.18818118188181182}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weat = WEAT()\n",
        "result = weat.run_query(\n",
        "    query,\n",
        "    gender_debiased_model,\n",
        "    calculate_p_value=True,\n",
        ")\n",
        "result"
      ],
      "metadata": {
        "id": "l0Z8GU5vNUt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b3d140-5acc-44ed-84ba-797c87a3325c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': 0.006566311581991613,\n",
              " 'weat': 0.006566311581991613,\n",
              " 'effect_size': 0.00667966690685079,\n",
              " 'p_value': 0.49495050494950504}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weat = WEAT()\n",
        "result = weat.run_query(\n",
        "    query,\n",
        "    debiased_model,\n",
        "    calculate_p_value=True,\n",
        ")\n",
        "result\n"
      ],
      "metadata": {
        "id": "xlE_VlHJNY3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db88966d-de2b-4668-d742-23b4cfebfcd1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query_name': 'Female Terms and Male Terms wrt Arts and Science',\n",
              " 'result': -0.10798480443190783,\n",
              " 'weat': -0.10798480443190783,\n",
              " 'effect_size': -0.11753826253471557,\n",
              " 'p_value': 0.583941605839416}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Fair Embedding Engine\n"
      ],
      "metadata": {
        "id": "JxsaPvnbFOkk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of Fair Embedding Engine, the embedding model is delivered at the time of instantiating the algorithm. FEE does not allow the user to provide definitional pairs, so it only works on gender bias, since the word sets they use is for this type of bias.\n",
        "\n",
        "To apply the debias is as simple as executing the run method to the algorithm, in which a word list corresponding to the word that the debias proccess will be applied, must be provided."
      ],
      "metadata": {
        "id": "iw5b0TTtq-Ef"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from FEE.fee.debias import HardDebias, RANDebias"
      ],
      "metadata": {
        "id": "u3pE-MM9F391"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fee_model.normalize() #model must be normalized"
      ],
      "metadata": {
        "id": "n7qtkGKmjlWD"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "HD = copy.deepcopy(fee_model)\n",
        "# instance the algortihm and apply it to the embedding model\n",
        "HD = HardDebias(HD).run(word_list=targets) "
      ],
      "metadata": {
        "id": "mhTYQguqQC2a"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEE allows to use different algortihms in a very similar way."
      ],
      "metadata": {
        "id": "88TOWvYZ7Sek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RAN = copy.deepcopy(fee_model)\n",
        "RAN = RANDebias(RAN).run(words=targets)"
      ],
      "metadata": {
        "id": "gmXCTA6m6_Y_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50ab2259-eaa8-49ec-97e3-fc05ee6202e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/FEE/fee/debias/ran_debias.py:126: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  self.sel = torch.FloatTensor(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comparing bias in the models."
      ],
      "metadata": {
        "id": "aE_ArwdN3RY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fee_weat = FEE_WEAT(fee_model)\n",
        "\n",
        "fee_weat.compute(female_terms, male_terms, family_terms, career_terms)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnpmA54_uhvO",
        "outputId": "7a78c23d-8f3a-4cc5-e707-05c6db879ce5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.45076525"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fee_weat = FEE_WEAT(HD)\n",
        "\n",
        "fee_weat.compute(female_terms, male_terms, family_terms, career_terms)"
      ],
      "metadata": {
        "id": "IvpPmcP6Oitr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "facd42c1-6a53-45f8-8a52-c030bfba5c3e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.056027465"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from FEE.fee.metrics import WEAT as FEE_WEAT\n",
        "fee_weat = FEE_WEAT(RAN)\n",
        "\n",
        "fee_weat.compute(female_terms, male_terms, family_terms, career_terms)"
      ],
      "metadata": {
        "id": "vwtp3bIdOmey",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e1a8b4-cc54-4efb-d44a-6acbf81e3776"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.039264895"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Responsibly\n"
      ],
      "metadata": {
        "id": "iNIx_ckVFPDS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the case of Responsibly IA, the embedding model is delivered at the time of instantiating the GenderBiasWe class. Responsibly does not allow the user to provide definitional pairs, the bias to mitigate is set to gender bias.\n",
        "\n",
        "To perform the debias it is as simple to execute the debias method."
      ],
      "metadata": {
        "id": "-FEQlwZx4190"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bias in the model before applying the algortihm\n",
        "calc_single_weat(\n",
        "    word2vec,\n",
        "    first_target={\"name\": \"female_terms\", \"words\": female_terms},\n",
        "    second_target={\"name\": \"male_terms\", \"words\": male_terms},\n",
        "    first_attribute={\"name\": \"family_terms\", \"words\": family_terms},\n",
        "    second_attribute={\"name\": \"career_terms\", \"words\": career_terms},\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YU72JAXMYIoz",
        "outputId": "47393256-6cc0-4ae4-c3cb-eb2098a807a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Target words': 'female_terms vs. male_terms',\n",
              " 'Attrib. words': 'family_terms vs. career_terms',\n",
              " 's': 0.46343886107206345,\n",
              " 'd': 0.45076525,\n",
              " 'p': 0.19704739704739704,\n",
              " 'Nt': '8x2',\n",
              " 'Na': '8x2'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from responsibly.we import GenderBiasWE"
      ],
      "metadata": {
        "id": "ygrY-7P3UgIP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gender_bias_we = GenderBiasWE(word2vec) # instance the GenderBiasWE\n",
        "gender_bias_we.debias(neutral_words=targets) # apply the debias"
      ],
      "metadata": {
        "id": "G7Lr0CGnUkLy"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The debias applied corresponds to Hard Debias, wich es the only one implemented in the library."
      ],
      "metadata": {
        "id": "LicHgU-iRLuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bias in the model after applying the algortihm\n",
        "calc_single_weat(\n",
        "    word2vec,\n",
        "    first_target={\"name\": \"female_terms\", \"words\": female_terms},\n",
        "    second_target={\"name\": \"male_terms\", \"words\": male_terms},\n",
        "    first_attribute={\"name\": \"family_terms\", \"words\": family_terms},\n",
        "    second_attribute={\"name\": \"career_terms\", \"words\": career_terms},\n",
        ")"
      ],
      "metadata": {
        "id": "7L9i8Z3iOpol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6db296ec-64b5-4865-d8a3-9af2021895ba"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Target words': 'female_terms vs. male_terms',\n",
              " 'Attrib. words': 'family_terms vs. career_terms',\n",
              " 's': 0.047348424792289734,\n",
              " 'd': 0.04824888,\n",
              " 'p': 0.4641025641025641,\n",
              " 'Nt': '8x2',\n",
              " 'Na': '8x2'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One problem found in Responsibly is that if wanted to perform the debias process over an embedding that does not include one of the words included in the library as definitional pairs, an error occurs.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0L05YI8hP2bR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gender_bias_we = GenderBiasWE(twitter_25) \n",
        "gender_bias_we.debias() "
      ],
      "metadata": {
        "id": "n5DFPYpFP1-r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "6283a3e6-1218-4f81-eb88-df5ccf3b3ab1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-11395268009d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgender_bias_we\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenderBiasWE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mgender_bias_we\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebias\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/responsibly-0.1.3-py3.8.egg/responsibly/we/bias.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, only_lower, verbose, identify_direction, to_normalize)\u001b[0m\n\u001b[1;32m   1118\u001b[0m                 \u001b[0mdefinitional\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'definitional_pairs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             self._identify_direction('she', 'he',\n\u001b[0m\u001b[1;32m   1121\u001b[0m                                      \u001b[0mdefinitional\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m                                      identify_direction)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/responsibly-0.1.3-py3.8.egg/responsibly/we/bias.py\u001b[0m in \u001b[0;36m_identify_direction\u001b[0;34m(self, positive_end, negative_end, definitional, method)\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'pca'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m             \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_identify_subspace_by_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefinitional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_ratio_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mFIRST_PC_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                 raise RuntimeError('The Explained variance'\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/responsibly-0.1.3-py3.8.egg/responsibly/we/bias.py\u001b[0m in \u001b[0;36m_identify_subspace_by_pca\u001b[0;34m(self, definitional_pairs, n_components)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mword1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdefinitional_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m             \u001b[0mvector1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m             \u001b[0mvector2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/responsibly-0.1.3-py3.8.egg/responsibly/we/bias.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, entities)\u001b[0m\n\u001b[1;32m    335\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mentity\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 455\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwords_closer_than\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"word 'Mary' not in vocabulary\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "All three libraries provide a simple way of applying the bias mitigation algorithms in a similar way and all of them are able to mitigate bias in the word embedding model by similar amounts, according to the metric used. The major differences among them is that WEFE gives more power to the users allowing them to choose the bias criteria to mitigate, while FEE and Responsibly only work on gender bias. In addition, WEFE includes more algorithms than the other two frameworks."
      ],
      "metadata": {
        "id": "YFVpfREN7_T5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Algorithm               | WEFE | FEE | Responsibly | EmbeddingBiasScores |\n",
        "|-------------------------|------|-----|-------------|---------------------|\n",
        "| Hard Debias             | ✔    | ✔   | ✔           | ✖                   |\n",
        "| Double Hard Debias      | ✔    | ✖   | ✖           | ✖                   |\n",
        "| Half Sibling Regression | ✔    | ✔   | ✖           | ✖                   |\n",
        "| RAN                     | ✔    | ✔   | ✖           | ✖                   |\n",
        "| Multiclass HD           | ✔    | ✖   | ✖           | ✖                   |\n"
      ],
      "metadata": {
        "id": "oXA-TbNA4oRI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|                                                | WEFE                                    | FEE                                                                  | Responsibly                               | EmbeddingBiasScores                |\n",
        "|------------------------------------------------|-----------------------------------------|----------------------------------------------------------------------|-------------------------------------------|------------------------------------|\n",
        "| Implemented   Metrics                          | 7                                       | 7                                                                    | 3                                         |                                  6 |\n",
        "| Implemented   Debias Algorithms                | 5                                       | 3                                                                    | 1                                         |                                  0 |\n",
        "| Extensible                                     | Easy                                    | Easy                                                                 | Difficult,   not very modular.            | Easy                               |\n",
        "| Well-defined   interface for metrics           | ✔                                       | ✖                                                                    | ✖                                         | ✔                                  |\n",
        "| Well-defined   interface for debias algorithms | ✔                                       | ✖                                                                    | ✖                                         | ✖                                  |\n",
        "| Update                               | Updated                                 | Outdated                                                             | Outdated                                  | Updated                            |\n",
        "| installation                                        | Easy:   pip or conda                    | There   are no instructions. It can be installed from the repository | Only   with pip. Presents problems        | Only   from the repository         |\n",
        "| Documentation                                  | Extensive   documentation with examples | Almost   no documentation                                            |  Limited documentation with some examples | No   documentation, only examples. |"
      ],
      "metadata": {
        "id": "D6d2tAewTwtn"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "wefe",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "37d01894bb315c73bf6fde5551d8a97078996f38b23395695bd1998fb0ae5507"
      }
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}