#############################################
Rank several embeddings on different criteria
#############################################

The following code replicates the execution of the paper's case study: 

P. Badilla, F. Bravo-Marquez, and J. PÃ©rez 
WEFE: The Word Embeddings Fairness Evaluation Framework In Proceedings of the
29th International Joint Conference on Artificial Intelligence and the 17th 
Pacific Rim International Conference on Artificial Intelligence (IJCAI-PRICAI 2020), Yokohama, Japan. 


In this experiment they are evaluated: 

- Multiple queries grouped under different criteria (gender, ethnicity, religion)
- Multiple embeddings
- Multiple metrics. 

From the results grouped by query criteria, rankings of the bias that was 
detected in each embedding model are generated by metric and plotted. 
An overall is included, which is simply the sum of all the rankings by 
model and by metric.

Finally, the matrix of correlations between these rankings is calculated and plotted.

The code of this experiment is relatively long, as is the time of its execution.
You can see it in his Jupyter Notebook using the following `link <https://github.com/dccuchile/wefe/blob/master/examples/WEFE_rankings.ipynb>`_.
