{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(bias measurement)=\n",
    "\n",
    "# Bias Measurement\n",
    "\n",
    "The following guide is designed to present the more general details on\n",
    "using the package to measure bias. The following sections show:\n",
    "\n",
    "*  how to run a simple query using ``Glove`` embedding model.\n",
    "*  how to run multiple queries on multiple embeddings.\n",
    "*  how to compare the results obtained from running multiple\n",
    "   sets of queries on multiple embeddings using different metrics\n",
    "   through ranking calculation.\n",
    "*  how to calculate the correlations between the\n",
    "   rankings obtained.\n",
    "\n",
    "\n",
    ":::{warning}\n",
    "\n",
    "  To accurately study and reduce biases contained in word embeddings, queries may\n",
    "  contain words that could be offensive to certain groups or individuals.\n",
    "  The relationships studied between these words DO NOT represent the\n",
    "  ideas, thoughts or beliefs of the authors of this library. \n",
    "  This warning applies to all documentation.\n",
    "\n",
    ":::\n",
    "\n",
    "\n",
    ":::{note}\n",
    "\n",
    "If you are not familiar with the concepts of query, target and attribute\n",
    "set, please visit the {ref}`measurement framework`\n",
    "on the library’s conceptual guides. These concepts are widely used in the\n",
    "following sections.\n",
    "\n",
    ":::\n",
    "\n",
    ":::{note}\n",
    "\n",
    "For a list of metrics implemented in WEFE, refer to the\n",
    "[metrics section](metrics-API) of the API reference.  \n",
    "\n",
    ":::\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Run a Query\n",
    "\n",
    "The following subsections explains how to run a simple query that\n",
    "measures gender bias on\n",
    "[Glove](https://nlp.stanford.edu/projects/glove/). The example uses\n",
    "the Word Embedding Association Test ({class}`~wefe.metrics.WEAT.WEAT`) metric\n",
    "quantifying the bias in the embeddings model. Below we show the three usual steps for\n",
    "performing a query in WEFE:\n",
    "\n",
    ":::{note}\n",
    "\n",
    "{class}`~wefe.metrics.WEAT.WEAT` is a fairness metric that quantifies the relationship\n",
    "between two sets of target words (sets of words intended to denote a social\n",
    "groups as men and women) and two sets of attribute words (sets of words\n",
    "representing some attitude, characteristic, trait, occupational field,\n",
    "etc. that can be associated with individuals from any social group). \n",
    "\n",
    "The closer its value is to 0, the less biased the model is. \n",
    "\n",
    "Visit the metrics documentation ({class}`~wefe.metrics.WEAT.WEAT`) for more information.\n",
    "\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a word embeddings model as a ``WordEmbeddingModel`` object.\n",
    "\n",
    "Load the word embedding model and then wrap it using a\n",
    "{class}`~wefe.word_embedding_model.WordEmbeddingModel` (class that allows WEFE to handle the models).\n",
    "\n",
    "WEFE bases all its operations on word embeddings using Gensim’s\n",
    "``KeyedVectors`` interface. Any model that can be loaded using\n",
    "``KeyedVectors`` will be compatible with WEFE. The following example uses a 25-dim pre-trained ``Glove`` model using a\n",
    "twitter dataset loaded using [gensim-data](https://github.com/RaRe-Technologies/gensim-data/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "from wefe.datasets import load_weat\n",
    "from wefe.metrics import WEAT\n",
    "from wefe.query import Query\n",
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "\n",
    "twitter_25 = api.load(\"glove-twitter-25\")\n",
    "# WordEmbeddingModel receives as first argument a KeyedVectors model\n",
    "# and the second argument the model name.\n",
    "model = WordEmbeddingModel(twitter_25, \"glove twitter dim=25\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the query using a ``Query`` object\n",
    "\n",
    "Define the target and attribute word sets and create a {class}`~wefe.query.Query`  object\n",
    "that contains them.\n",
    "\n",
    "For this initial example, a query is used to study the association\n",
    "between gender with respect to family and career. The words used are\n",
    "taken from the set of words used in the *Semantics derived automatically\n",
    "from language corpora contain human-like biases* paper, which are\n",
    "included in the ``datasets`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_query = Query(\n",
    "    target_sets=[\n",
    "        [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"],\n",
    "        [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"],\n",
    "    ],\n",
    "    attribute_sets=[\n",
    "        [\n",
    "            \"home\",\n",
    "            \"parents\",\n",
    "            \"children\",\n",
    "            \"family\",\n",
    "            \"cousins\",\n",
    "            \"marriage\",\n",
    "            \"wedding\",\n",
    "            \"relatives\",\n",
    "        ],\n",
    "        [\n",
    "            \"executive\",\n",
    "            \"management\",\n",
    "            \"professional\",\n",
    "            \"corporation\",\n",
    "            \"salary\",\n",
    "            \"office\",\n",
    "            \"business\",\n",
    "            \"career\",\n",
    "        ],\n",
    "    ],\n",
    "    target_sets_names=[\"Female terms\", \"Male Terms\"],\n",
    "    attribute_sets_names=[\"Family\", \"Careers\"],\n",
    ")\n",
    "\n",
    "gender_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the Query\n",
    "\n",
    "Instantiate the metric that you will use and then execute ``run_query``\n",
    "with the parameters created in the previous steps.\n",
    "\n",
    "Any bias measurement process at WEFE consists of the following steps:\n",
    "\n",
    "1. Metric arguments checking.\n",
    "2. Transform the word sets into word embeddings.\n",
    "3. Calculate the metric.\n",
    "\n",
    "In this case we use the {class}`~wefe.metrics.WEAT.WEAT` metric (proposed in the\n",
    "same paper of the set of words used in the query)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = WEAT()\n",
    "result = metric.run_query(gender_query, model)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "By default, the results are a ``dict`` containing the query name (in the\n",
    "key ``query_name``) and the calculated value of the metric in the\n",
    "``result`` key. It also contains a key with the name and the value of\n",
    "the calculated metric (which is duplicated in the “results” key).\n",
    "\n",
    "Depending on the metric class used, the result ``dict`` can also return\n",
    "more metrics, detailed word-by-word values or other statistics like\n",
    "p-values. Also some metrics allow you to change the default value in\n",
    "results.\n",
    "\n",
    "Details of all the metrics implemented, their parameters and\n",
    "examples of execution can be found at [metrics section](metrics-API)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Query Arguments\n",
    "\n",
    "Each metric allows varying the behavior of ``run_query`` according to\n",
    "different parameters. There are parameters to customize the\n",
    "transformation of the sets of words to sets of embeddings, others to\n",
    "warn errors or modify which calculation method the metric use.\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Each metric implements the `run_query` method with different arguments. \n",
    "Visit their API documentation for more information.\n",
    ":::\n",
    "\n",
    "For example, ``run_query`` can be instructed to ``return effect_size``\n",
    "in the ``result`` key by setting ``return_effect_size`` as ``True``.\n",
    "Note that this parameter is only of the class ``WEAT``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(gender_query, model, return_effect_size=True)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also request ``run_query`` to run the statistical significance\n",
    "calculation by setting ``calculate_p_value`` as ``True``. This checks\n",
    "how many queries generated from permutations (controlled by the\n",
    "parameter ``p_value_iterations``) of the target sets obtain values\n",
    "greater than those obtained by the original query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    gender_query, model, calculate_p_value=True, p_value_iterations=5000\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Out of Vocabulary Words\n",
    "\n",
    "It is common in the literature to find bias tests whose tagret sets are\n",
    "common names of social groups. These names are commonly cased and may\n",
    "contain special characters. There are several embedding models whose\n",
    "words are not cased or do not have accents or other special characters,\n",
    "as for example, in ``Glove``. This implies that a query with target sets\n",
    "composed by names executed in ``Glove`` (without any preprocessing of\n",
    "the words) could produce erroneous results because WEFE will not be able\n",
    "to find the names in the model vocabulary.\n",
    "\n",
    "\n",
    ":::{note}\n",
    "\n",
    "\n",
    "Some well-known word sets are already provided by the package and can be\n",
    "easily loaded by the user through the [datasets](datasets-API)  module. From here on,\n",
    "the tutorial use the words defined in the study *Semantics derived\n",
    "automatically from language corpora contain human-like biases*, the same\n",
    "that proposed the {class}`~wefe.metrics.WEAT.WEAT` metric.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the weat word sets.\n",
    "word_sets = load_weat()\n",
    "\n",
    "# print a set of european american common names.\n",
    "print(word_sets[\"european_american_names_5\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following query compares European-American and African-American\n",
    "names with respect to pleasant and unpleasant attributes.\n",
    "\n",
    "\n",
    ":::{note}\n",
    "\n",
    "\n",
    "It can be indicated to ``run_query`` to log the words that were lost in\n",
    "the transformation to vectors by using the parameter\n",
    "``warn_not_found_words`` as ``True``.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ethnicity_query = Query(\n",
    "    [word_sets[\"european_american_names_5\"], word_sets[\"african_american_names_5\"]],\n",
    "    [word_sets[\"pleasant_5\"], word_sets[\"unpleasant_5\"]],\n",
    "    [\"European american names\", \"African american names\"],\n",
    "    [\"Pleasant\", \"Unpleasant\"],\n",
    ")\n",
    "result = weat.run_query(ethnicity_query, model, warn_not_found_words=True,)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{warning}\n",
    "\n",
    "If more than 20% of the words from any of the word sets of the query are\n",
    "lost during the transformation to embeddings, the result of the metric\n",
    "will be ``np.nan``. This behavior can be changed using a float number\n",
    "parameter called ``lost_vocabulary_threshold``.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Preprocessors\n",
    "\n",
    "``run_queries`` allows preprocessing each word before they are searched in the model's \n",
    "vocabulary.through the parameter ``preprocessors``. (list of one or more preprocessor).\n",
    "This parameter accepts a list of individual preprocessors, which are defined below:\n",
    "\n",
    "A ``preprocessor`` is a dictionary that specifies what processing(s) are \n",
    "performed on each word before its looked up in the model vocabulary.\n",
    "For example, the ``preprocessor``\n",
    "``{'lowecase': True, 'strip_accents': True}`` allows you to lowercase\n",
    "and remove the accent from each word before searching for them in the\n",
    "model vocabulary. Note that an empty dictionary ``{}`` indicates that no\n",
    "preprocessing is done.\n",
    "\n",
    "The possible options for a preprocessor are:\n",
    "\n",
    "*  ``lowercase``: ``bool``. Indicates that the words are transformed to lowercase.\n",
    "*  ``uppercase``: ``bool``. Indicates that the words are transformed to uppercase.\n",
    "*  ``titlecase``: ``bool``. Indicates that the words are transformed to titlecase.\n",
    "*  ``strip_accents``: ``bool``, ``{'ascii', 'unicode'}``: Specifies that the accents of the words are eliminated. The stripping type can be specified. True uses ‘unicode’ by default.\n",
    "*  ``preprocessor``: ``Callable``. It receives a function that operates on each word. In the case of specifying a function, it overrides the default preprocessor (i.e., the previous options stop working).\n",
    "\n",
    "\n",
    "A list of preprocessor options allows searching for several\n",
    "variants of the words into the model. For example, the preprocessors\n",
    "``[{}, {\"lowercase\": True, \"strip_accents\": True}]``\n",
    "``{}`` allows first to search for the original words in the vocabulary of the model. \n",
    "In case some of them are not found, ``{\"lowercase\": True, \"strip_accents\": True}`` \n",
    "is executed on these words and then they are searched in the model vocabulary.\n",
    "\n",
    "By default (in case there is more than one preprocessor in the list) the first \n",
    "preprocessed word found in the embeddings model is used. \n",
    "This behavior can be controlled by the ``strategy`` parameter of ``run_query``.\n",
    "\n",
    "In the following example, we provide a list with only one\n",
    "preprocessor that instructs ``run_query`` to lowercase and remove all\n",
    "accents from every word before they are searched in the embeddings\n",
    "model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    ethnicity_query,\n",
    "    model,\n",
    "    preprocessors=[{\"lowercase\": True, \"strip_accents\": True}],\n",
    "    warn_not_found_words=True,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It may happen that it is more important to find the original word and in\n",
    "the case of not finding it, then preprocess it and look it up in the\n",
    "vocabulary. This behavior can be specified in ``preprocessors`` list by\n",
    "first specifying an empty preprocessor ``{}`` and then the preprocessor\n",
    "that converts to lowercase and removes accents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    ethnicity_query,\n",
    "    model,\n",
    "    preprocessors=[\n",
    "        {},  # empty preprocessor, search for the original words.\n",
    "        {\n",
    "            \"lowercase\": True,\n",
    "            \"strip_accents\": True,\n",
    "        },  # search for lowercase and no accent words.\n",
    "    ],\n",
    "    warn_not_found_words=True,\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of preprocessing steps can be increased as needed. For\n",
    "example, we can complex the above preprocessor to first search for the\n",
    "original words, then for the lowercase words, and finally for the\n",
    "lowercase words without accents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    ethnicity_query,\n",
    "    model,\n",
    "    preprocessors=[\n",
    "        {},  # first step: empty preprocessor, search for the original words.\n",
    "        {\"lowercase\": True,},  # second step: search for lowercase.\n",
    "        {\n",
    "            \"lowercase\": True,\n",
    "            \"strip_accents\": True,\n",
    "        },  # third step: search for lowercase and no accent words.\n",
    "    ],\n",
    "    warn_not_found_words=True,\n",
    ")\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to change the behavior of the search by including\n",
    "not only the first word, but all the words generated by the\n",
    "preprocessors. This can be controlled by specifying the parameter\n",
    "``strategy=all``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    ethnicity_query,\n",
    "    model,\n",
    "    preprocessors=[\n",
    "        {},  # first step: empty preprocessor, search for the original words.\n",
    "        {\"lowercase\": True,},  # second step: search for lowercase .\n",
    "        {\"uppercase\": True,},  # third step: search for uppercase.\n",
    "    ],\n",
    "    strategy=\"all\",\n",
    "    warn_not_found_words=True,\n",
    ")\n",
    "\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Multiple Queries\n",
    "\n",
    "\n",
    "It is usual to want to test many queries of some bias criterion (gender,\n",
    "ethnicity, religion, politics, socioeconomic, among others) on several\n",
    "models at the same time. Trying to use ``run_query`` on each pair\n",
    "embedding-query can be a bit complex and could require extra work to\n",
    "implement.\n",
    "\n",
    "This is why the library also implements a function to test multiple\n",
    "queries on various word embedding models in a single call: the\n",
    "``run_queries`` util.\n",
    "\n",
    "The following code shows how to run various gender queries on ``Glove``\n",
    "embedding models with different dimensions trained from the Twitter\n",
    "dataset. The queries are executed using {class}`~wefe.metrics.WEAT.WEAT` metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "from wefe.datasets import load_weat\n",
    "from wefe.metrics import RNSB, WEAT\n",
    "from wefe.query import Query\n",
    "from wefe.utils import run_queries\n",
    "from wefe.word_embedding_model import WordEmbeddingModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the models\n",
    "\n",
    "Load three different Glove Twitter embedding models. These models were\n",
    "trained using the same dataset varying the number of embedding\n",
    "dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = WordEmbeddingModel(api.load(\"glove-twitter-25\"), \"glove twitter dim=25\")\n",
    "model_2 = WordEmbeddingModel(api.load(\"glove-twitter-50\"), \"glove twitter dim=50\")\n",
    "model_3 = WordEmbeddingModel(api.load(\"glove-twitter-100\"), \"glove twitter dim=100\")\n",
    "\n",
    "models = [model_1, model_2, model_3]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the word sets and create the queries\n",
    "\n",
    "Now, we load the ``WEAT`` word set and create three queries. The\n",
    "three queries are intended to measure gender bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the WEAT word sets\n",
    "word_sets = load_weat()\n",
    "\n",
    "# Create gender queries\n",
    "gender_query_1 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"career\"], word_sets[\"family\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Career\", \"Family\"],\n",
    ")\n",
    "\n",
    "gender_query_2 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"science\"], word_sets[\"arts\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Science\", \"Arts\"],\n",
    ")\n",
    "\n",
    "gender_query_3 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"math\"], word_sets[\"arts_2\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Math\", \"Arts\"],\n",
    ")\n",
    "\n",
    "gender_queries = [gender_query_1, gender_query_2, gender_query_3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the queries on all Word Embeddings using WEAT.\n",
    "\n",
    "To run the list of queries and models, we call ``run_queries`` using the\n",
    "parameters defined in the previous step. The mandatory parameters of the\n",
    "function are 3:\n",
    "\n",
    "-  a metric,\n",
    "-  a list of queries, and,\n",
    "-  a list of embedding models.\n",
    "\n",
    "It is also possible to provide a name for the criterion studied in this\n",
    "set of queries through the parameter ``queries_set_name``.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAT_gender_results = run_queries(\n",
    "    WEAT, gender_queries, models, queries_set_name=\"Gender Queries\"\n",
    ")\n",
    "WEAT_gender_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting metric params\n",
    "\n",
    "There is a whole column that has no results. As the warnings point out,\n",
    "when transforming the words of the sets into embeddings, there is a loss\n",
    "of words that is greater than the allowed by the parameter\n",
    "``lost_vocabulary_threshold``. In this case, it would be very useful to\n",
    "use the word preprocessors seen above.\n",
    "\n",
    "``run_queries``, accept specific parameters for each metric. These extra\n",
    "parameters for the metric can be passed through ``metric_params``\n",
    "parameter. In this case, a ``preprocessor`` is provided to lowercase the\n",
    "words before searching for them in the models’ vocabularies.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "WEAT_gender_results = run_queries(\n",
    "    WEAT,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")\n",
    "\n",
    "WEAT_gender_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No query was null in these results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plot the results in a barplot\n",
    "\n",
    "\n",
    "The library also provides an easy way to plot the results obtained from\n",
    "a ``run_queries`` execution into a [plotly](https://plotly.com/python/) braplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.utils import plot_queries_results, run_queries\n",
    "\n",
    "# Plot the results\n",
    "plot_queries_results(WEAT_gender_results).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregating Results\n",
    "\n",
    "The execution of ``run_queries`` provided many results evaluating the\n",
    "gender bias in the tested embeddings. However, these results alone do\n",
    "not comprehensively report the biases observed in all of these queries.\n",
    "One way to obtain an overall view of bias is by aggregating results by\n",
    "model.\n",
    "\n",
    "For WEAT, a simple way to aggregate the results is to average their\n",
    "absolute values. When running ``run_queries``, it is possible to specify\n",
    "that the results be aggregated by model by setting ``aggregate_results``\n",
    "as ``True``\n",
    "\n",
    "The aggregation function can be specified through the\n",
    "``aggregation_function`` parameter. This parameter accepts a list of\n",
    "predefined aggregations as well as a custom function that operates on\n",
    "the results dataframe. The aggregation functions available are:\n",
    "\n",
    "-  Average ``avg``.\n",
    "-  Average of the absolute values ``abs_avg``.\n",
    "-  Sum ``sum``.\n",
    "-  Sum of the absolute values, ``abs_sum``.\n",
    "\n",
    ":::{note}\n",
    "\n",
    "Notice that some functions are more appropriate for certain metrics. For\n",
    "metrics returning only positive numbers, all the previous aggregation\n",
    "functions would be OK. In contrast, metrics that return real values\n",
    "(e.g., {class}`~wefe.metrics.WEAT.WEAT` , {class}`~wefe.metrics.RND.RND` , etc…), \n",
    "aggregation functions such as sum would make positive and negative outputs to cancel \n",
    "each other.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAT_gender_results_agg = run_queries(\n",
    "    WEAT,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    aggregation_function=\"abs_avg\",\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")\n",
    "WEAT_gender_results_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_queries_results(WEAT_gender_results_agg).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to ask the function to return only the aggregated\n",
    "results using the parameter ``return_only_aggregation``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WEAT_gender_results_only_agg = run_queries(\n",
    "    WEAT,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    aggregation_function=\"abs_avg\",\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")\n",
    "WEAT_gender_results_only_agg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_queries_results(WEAT_gender_results_only_agg)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Ranking\n",
    "\n",
    "It may be desirable to obtain an overall view of the bias by model using\n",
    "different metrics or bias criteria. While the aggregate values can be\n",
    "compared directly, two problems are likely to be encountered:\n",
    "\n",
    "1.  One type of bias criterion can dominate the other because of\n",
    "    significant differences in magnitude.\n",
    "\n",
    "2.  Different metrics can operate on different scales, which makes them\n",
    "    difficult to compare.\n",
    "\n",
    "To show these problems, suppose we have:\n",
    "\n",
    "-   Two sets of queries: one that explores gender biases and\n",
    "    another that explores ethnicity biases.\n",
    "-   Three ``Glove`` models of 25, 50 and 100 dimensions trained on the same\n",
    "    twitter dataset.\n",
    "\n",
    "Then we run ``run_queries`` on this set of model-queries using \n",
    "{class}`~wefe.metrics.WEAT.WEAT`, and to corroborate the results obtained, we also use \n",
    "Relative Negative Sentiment Bias ({class}`~wefe.metrics.RNSB.RNSB`).\n",
    "\n",
    "1.  The first problem occurs when the bias scores obtained from one set\n",
    "    of queries are much higher than those from the other set, even when\n",
    "    the same metric is used.\n",
    "\n",
    "When executing ``run_queries`` with the gender and ethnicity queries on\n",
    "the models described above, the results obtained are as follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model_name                             |           WEAT: Gender Queries average of abs values score              |           WEAT: Ethnicity Queries average of abs values score          |\n",
    "|----------------------------------------|-------------------------------------------------------------------------|------------------------------------------------------------------------|\n",
    "|           glove twitter dim=25         |                                     0.210556                            |                                     2.64632                            |\n",
    "|           glove twitter dim=50         |                                     0.292373                            |                                     1.87431                            |\n",
    "|           glove twitter dim=100        |                                     0.225116                            |                                     1.78469                            |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the results of ethnicity bias are much greater than\n",
    "those of gender.\n",
    "\n",
    "2.  The second problem is when different metrics return results on\n",
    "    different scales of magnitude.\n",
    "\n",
    "When executing ``run_queries`` with the gender queries and models\n",
    "described above using both WEAT and RNSB, the results obtained are as\n",
    "follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| model_name                             |           WEAT: Gender Queries average of abs values score              |           RNSB: Gender Queries average of abs values score              |\n",
    "|----------------------------------------|-------------------------------------------------------------------------|-------------------------------------------------------------------------|\n",
    "|           glove twitter dim=25         |                                     0.210556                            |                                     0.032673                            |\n",
    "|           glove twitter dim=50         |                                     0.292373                            |                                     0.049429                            |\n",
    "|           glove twitter dim=100        |                                     0.225116                            |                                     0.0312772                           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can see differences between the results of both metrics of an order\n",
    "of magnitude.\n",
    "\n",
    "One solution to this problem is to create **rankings**. Rankings focus on the relative\n",
    "differences reported by the metrics (for different models) instead of focusing on the\n",
    "absolute values.\n",
    "\n",
    "The following guide show how to create rankings that evaluate\n",
    "gender bias and ethnicity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender Bias Model Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the queries\n",
    "gender_query_1 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"career\"], word_sets[\"family\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Career\", \"Family\"],\n",
    ")\n",
    "gender_query_2 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"science\"], word_sets[\"arts\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Science\", \"Arts\"],\n",
    ")\n",
    "gender_query_3 = Query(\n",
    "    [word_sets[\"male_terms\"], word_sets[\"female_terms\"]],\n",
    "    [word_sets[\"math\"], word_sets[\"arts_2\"]],\n",
    "    [\"Male terms\", \"Female terms\"],\n",
    "    [\"Math\", \"Arts\"],\n",
    ")\n",
    "\n",
    "gender_queries = [gender_query_1, gender_query_2, gender_query_3]\n",
    "\n",
    "# run the queries using WEAT\n",
    "WEAT_gender_results = run_queries(\n",
    "    WEAT,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")\n",
    "\n",
    "# run the queries using WEAT effect size\n",
    "WEAT_EZ_gender_results = run_queries(\n",
    "    WEAT,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}], \"return_effect_size\": True,},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")\n",
    "\n",
    "# run the queries using RNSB\n",
    "RNSB_gender_results = run_queries(\n",
    "    RNSB,\n",
    "    gender_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Gender Queries\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rankings can be calculated by means of the ``create_ranking``\n",
    "function. This function receives as input results from running\n",
    "``run_queries`` and assumes that the last column contains the aggregated\n",
    "values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.utils import create_ranking\n",
    "\n",
    "# create the ranking\n",
    "gender_ranking = create_ranking(\n",
    "    [WEAT_gender_results, WEAT_EZ_gender_results, RNSB_gender_results]\n",
    ")\n",
    "\n",
    "gender_ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethnicity Bias Model Ranking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the queries\n",
    "ethnicity_query_1 = Query(\n",
    "    [word_sets[\"european_american_names_5\"], word_sets[\"african_american_names_5\"]],\n",
    "    [word_sets[\"pleasant_5\"], word_sets[\"unpleasant_5\"]],\n",
    "    [\"European Names\", \"African Names\"],\n",
    "    [\"Pleasant\", \"Unpleasant\"],\n",
    ")\n",
    "\n",
    "ethnicity_query_2 = Query(\n",
    "    [word_sets[\"european_american_names_7\"], word_sets[\"african_american_names_7\"]],\n",
    "    [word_sets[\"pleasant_9\"], word_sets[\"unpleasant_9\"]],\n",
    "    [\"European Names\", \"African Names\"],\n",
    "    [\"Pleasant 2\", \"Unpleasant 2\"],\n",
    ")\n",
    "\n",
    "ethnicity_queries = [ethnicity_query_1, ethnicity_query_2]\n",
    "\n",
    "# run the queries using WEAT\n",
    "WEAT_ethnicity_results = run_queries(\n",
    "    WEAT,\n",
    "    ethnicity_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Ethnicity Queries\",\n",
    ")\n",
    "\n",
    "# run the queries using WEAT effect size\n",
    "WEAT_EZ_ethnicity_results = run_queries(\n",
    "    WEAT,\n",
    "    ethnicity_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}], \"return_effect_size\": True,},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Ethnicity Queries\",\n",
    ")\n",
    "\n",
    "# run the queries using RNSB\n",
    "RNSB_ethnicity_results = run_queries(\n",
    "    RNSB,\n",
    "    ethnicity_queries,\n",
    "    models,\n",
    "    metric_params={\"preprocessors\": [{\"lowercase\": True}]},\n",
    "    aggregate_results=True,\n",
    "    return_only_aggregation=True,\n",
    "    queries_set_name=\"Ethnicity Queries\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the ranking\n",
    "ethnicity_ranking = create_ranking(\n",
    "    [WEAT_ethnicity_results, WEAT_EZ_gender_results, RNSB_ethnicity_results]\n",
    ")\n",
    "\n",
    "ethnicity_ranking\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the rankings\n",
    "\n",
    "It is possible to graph the rankings in barplots using the\n",
    "``plot_ranking`` function. The generated figure shows the accumulated\n",
    "rankings for each embedding model. Each bar represents the sum of the\n",
    "rankings obtained by each embedding. Each color within a bar represents\n",
    "a different criterion-metric ranking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.utils import plot_ranking\n",
    "\n",
    "fig = plot_ranking(gender_ranking)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_ranking(ethnicity_ranking)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlating Rankings\n",
    "\n",
    "Having obtained rankings by metric for each embeddings, it would be\n",
    "ideal to see and analyze the degree of agreement between them.\n",
    "\n",
    "A high concordance between the rankings allows us to state with some certainty that \n",
    "all metrics evaluated the embedding models in a similar way and therefore, \n",
    "that the ordering of embeddings by bias calculated makes sense.\n",
    "On the other hand, a low degree of agreement shows the opposite: the rankings do not \n",
    "allow to clearly establish which embedding is less biased than another.\n",
    "\n",
    "The level of concordance of the rankings can be evaluated by calculating\n",
    "correlations.WEFE provides ``calculate_ranking_correlations`` to\n",
    "calculate the correlations between rankings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.utils import calculate_ranking_correlations, plot_ranking_correlations\n",
    "\n",
    "correlations = calculate_ranking_correlations(gender_ranking)\n",
    "correlations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ":::{note}\n",
    "\n",
    "``calculate_ranking_correlations`` uses the ``corr()`` ``pandas``\n",
    "dataframe method. The type of correlation that is calculated can be changed \n",
    "through the method parameter. The available options are:\n",
    "``'pearson'``, ``'spearman'``, ``'kendall'``. By default, the spearman\n",
    "correlation is calculated.\n",
    "\n",
    ":::\n",
    "\n",
    "In this example, Kendall’s correlation is used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_ranking_correlations(gender_ranking, method=\"kendall\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WEFE also provides a function for graphing the correlations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_fig = plot_ranking_correlations(correlations)\n",
    "correlation_fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, only two of the three rankings show similar results.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('wefe')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37d01894bb315c73bf6fde5551d8a97078996f38b23395695bd1998fb0ae5507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
