{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark - WEFE, Fair Embedding Engine and Responsibly.AI\n",
    "\n",
    "To the best of our knowledge, there are only three other libraries besides WEFE that implement bias measurement and mitigation methods for word embeddings: Fair Embedding Engine (FEE), Responsibly, and EmbeddingBiasScores.\n",
    "\n",
    "According to its authors, Fair Embedding Engine is defined as \"A library for analyzing and mitigating gender bias in word embeddings\", Responsibly is defined as \"A toolkit for auditing and mitigating bias and fairness of machine learning systems\". Finally, EmbeddingBiasScores describes itself as a collection of implementations and wrappers of bias scores for text embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The documentation for these three libraries can be found at the following links:\n",
    "\n",
    "- https://github.com/FEE-Fair-Embedding-Engine/FEE\n",
    "- https://docs.responsibly.ai/\n",
    "- https://github.com/HammerLabML/EmbeddingBiasScores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benchmark presented here compares these three libraries against WEFE according to the following criteria:\n",
    "\n",
    "1. Ease of installation.\n",
    "2. Quality of the package and documentation.\n",
    "3. Ease of loading models.\n",
    "4. Ease of running bias measurements.\n",
    "5. Ease of running bias mitigation algorithms.\n",
    "6. Implemented metrics and mitigation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Ease of installation\n",
    "\n",
    "This comparison aims to evaluate how easy it is to install the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEFE\n",
    "\n",
    "According to the documentation, WEFE is available for installation using the Python Package Index (via pip) as well as via conda.\n",
    "\n",
    "\n",
    "```bash\n",
    "pip install --upgrade wefe\n",
    "# or\n",
    "conda install -c pbadilla wefe\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Embedding Engine\n",
    "\n",
    "In the case of FEE, neither the documentation nor the repository indicates how to install the package. Therefore, the easiest thing to do in this case is to clone the repository and then install the requirements , as described in the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Clone the repo\n",
    "```bash\n",
    "$ git clone https://github.com/FEE-Fair-Embedding-Engine/FEE\n",
    "```\n",
    "\n",
    "2. Install the requirements.\n",
    "```bash\n",
    "$ pip install -r FEE/requirements.txt\n",
    "$ pip install sympy\n",
    "$ pip install -U gensim==3.8.3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsibly\n",
    "\n",
    "According to its documentation, responsibly is hosted in the Python Package Index so it can be installed using pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ pip install responsibly\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmbeddingBiasScores\n",
    "\n",
    "In the case of EmbeddingBiasScores, the documentation indicates that the repository can be cloned and then installed locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "$ git clone https://github.com/HammerLabML/EmbeddingBiasScores.git\n",
    "$ pip install -r EmbeddingBiasScores/requirements.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "Both WEFE and Responsibly are hosted in the Python package index, which simplifies their installation and dependency handling, lowering the barrier to entry. FEE and EmbeddingBiasScores, on the other hand, require ad hoc installation procedures that require more advanced knowledge of Python and Pip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Source Code Quality and Documentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This benchmark seeks to compare the quality of documentation as well as other software quality features such as testing and continuous integration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEFE\n",
    "\n",
    "WEFE has a complete documentation site that explains in detail how to use the package: an about page with the motivation and goals of the project, a quick start page showing how to install the library, several user guides on how to measure and mitigate bias in word embeddings, a detailed API of the implemented methods, theoretical background in the area, and finally implementations of previous case studies.\n",
    "\n",
    "In addition, most of the code is tested and developed using continuous integration mechanisms (through a linter and testing mechanisms in Github Actions), which are well-established practices in software development.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fair Embedding Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEE' documentation covers only the basic aspects of the API and a flowchart showing the main concepts of the library. The documentation does not include user guides, code examples, or theoretical background on the implemented methods.\n",
    "\n",
    "In terms of software engineering practices and standards, no tests, linter, or continuous integration mechanisms could be identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsibly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responsibly has a complete documentation site that explains how to use the package: an index page with the main project information and a quick start page that shows how to install the library, demos that act as user manuals, and a detailed API of the implemented methods.\n",
    "\n",
    "In addition, most of the code is tested and developed using continuous integration mechanisms (through a linter and testing in Github Actions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmbeddingBiasScores\n",
    "\n",
    "It was not possible to find formal documentation explaining how to run bias tests in EmbeddingBiasScores. There is only a small Jupyter notebook with some use cases, which at the time of writing had several flaws that made it difficult to understand and use. \n",
    "\n",
    "No testing, linter, or continuous integration mechanisms could be identified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In terms of documentation, WEFE contains much more detailed documentation than the other libraries, with more extensive manuals and replications of previous case studies. Responsibly has sufficient documentation to execute its main functionalities without major problems, however, it is not as exhaustive as that of WEFE. FEE, only provides API documentation, which in our opinion is not sufficient for new users to use it without problems. Finally, EmbeddingBiasScores only presents a Jupyter notebook with some implementation examples. \n",
    "\n",
    "\n",
    "With respect to software quality, both FEE and Responsibly comply with well-established software development practices (i.e., testing, continuous integration, linter). FEE and EmbeddingBiasScores, on the other hand, do not have any of these practices in place\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ease of loading models\n",
    "\n",
    "In this section we will compare how easy it is to load a pre-trained word embedding (WE) model from each library. Two settings are compared: loading a model from Gensim's API (`glove-twitter-25`) and loading a model from a binary file (`word2vec`).\n",
    "\n",
    "\n",
    "The second setting requires downloading a WE model trained with the original word2vec implementation, which can be obtained as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/word2vec-google-news-300.gz\n",
    "# !gzip -dv word2vec-google-news-300.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEFE\n",
    "\n",
    "In WEFE, WE models are represented internally by wrapping Gensim models. This means that the model loading process (either from the API or from a file) is handled by Gensim loaders, while the class that generates the objects that allow access to the embeddings is managed by WEFE.\n",
    "\n",
    "\n",
    "The following code shows how to load a glove model using the Gensim API from within WEFE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "import gensim.downloader as api\n",
    "\n",
    "# load glove\n",
    "twitter_25 = api.load(\"glove-twitter-25\")\n",
    "model = WordEmbeddingModel(twitter_25, \"glove twitter dim=25\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how to load a word2vec model trained with the original implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "# load word2vec\n",
    "word2vec = api.load(\"word2vec-google-news-300\")\n",
    "model = WordEmbeddingModel(word2vec, \"word2vec-google-news-300\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEE\n",
    "\n",
    "FEE also offers direct support for loading WE models from its API through the following code. In this case, model loading is coupled to the WE class, which provides the methods to access the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FEE.fee.embedding.loader import WE\n",
    "\n",
    "fee_model = WE().load(ename=\"glove-twitter-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FEE.fee.embedding.loader import WE\n",
    "\n",
    "fee_model = WE().load(fname=\"word2vec-google-news-300\", format=\"bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsibly and EmbeddingBiasScores\n",
    "\n",
    "Neither Responsibly nor EmbeddingBiasScores implement their own interfaces to handle WE models. Users must rely on Gensim or other external libraries for this purpose. This can be expressed as shown in the following script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load twitter_25 model from gensim api\n",
    "twitter_25 = api.load(\"glove-twitter-25\")\n",
    "\n",
    "# load word2vec model from file\n",
    "word2vec = KeyedVectors.load_word2vec_format(\"word2vec-google-news-300\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed above, both WEFE and FEE implement their own interfaces to internally manage access to WE models. Responsibly and EmbeddingBiasScores lack such functionalities, which may complicate their use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Ease of running bias measurements. \n",
    "\n",
    "The following section aims to compare the execution of fairness metrics in the libraries included in this study. To make the benchmark as objective as possible, the set of words and the WE model are kept fixed throughout the comparison, and only the metrics are allowed to vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words to evaluate\n",
    "\n",
    "female_terms = [\"female\", \"woman\", \"girl\", \"sister\", \"she\", \"her\", \"hers\", \"daughter\"]\n",
    "male_terms = [\"male\", \"man\", \"boy\", \"brother\", \"he\", \"him\", \"his\", \"son\"]\n",
    "\n",
    "family_terms = [\n",
    "    \"home\",\n",
    "    \"parents\",\n",
    "    \"children\",\n",
    "    \"family\",\n",
    "    \"cousins\",\n",
    "    \"marriage\",\n",
    "    \"wedding\",\n",
    "    \"relatives\",\n",
    "]\n",
    "career_terms = [\n",
    "    \"executive\",\n",
    "    \"management\",\n",
    "    \"professional\",\n",
    "    \"corporation\",\n",
    "    \"salary\",\n",
    "    \"office\",\n",
    "    \"business\",\n",
    "    \"career\",\n",
    "]\n",
    "\n",
    "# optional, only for wefe usage.\n",
    "target_sets_names = [\"Female terms\", \"Male terms\"]\n",
    "attribute_sets_names = [\"Family terms\", \"Career terms\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WEFE\n",
    "\n",
    "WEFE defines a standardized framework for executing metrics: in short, it is necessary to define a query that will act as a container for the words to be tested and then, together with the model, will be provided as input to some metric.\n",
    "\n",
    "The outputs of the metrics are contained in dictionaries that allow additional metadata to be included to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Query: Female terms and Male terms wrt Family terms and Career terms\n",
       "- Target sets: [['female', 'woman', 'girl', 'sister', 'she', 'her', 'hers', 'daughter'], ['male', 'man', 'boy', 'brother', 'he', 'him', 'his', 'son']]\n",
       "- Attribute sets:[['home', 'parents', 'children', 'family', 'cousins', 'marriage', 'wedding', 'relatives'], ['executive', 'management', 'professional', 'corporation', 'salary', 'office', 'business', 'career']]>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the modules\n",
    "from wefe.query import Query\n",
    "\n",
    "# 1. create the query\n",
    "query = Query(\n",
    "    [female_terms, male_terms],\n",
    "    [family_terms, career_terms],\n",
    "    target_sets_names,\n",
    "    attribute_sets_names,\n",
    ")\n",
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male terms wrt Family terms and Career terms',\n",
       " 'result': 0.46343881433131173,\n",
       " 'weat': 0.46343881433131173,\n",
       " 'effect_size': 0.4507652792646716,\n",
       " 'p_value': nan}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wefe.metrics.WEAT import WEAT\n",
    "\n",
    "# 2. instance a WEAT metric and pass the query plus the model.\n",
    "weat = WEAT()\n",
    "result = weat.run_query(query, model)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the `run_query` method is independent of the query and the model, it can receive additional parameters that customize the process. In this case, we show how to normalize the words before searching for them in the model (i.e., lowercase them and remove their accents)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male terms wrt Family terms and Career terms',\n",
       " 'result': 0.46343881433131173,\n",
       " 'weat': 0.46343881433131173,\n",
       " 'effect_size': 0.4507652792646716,\n",
       " 'p_value': nan}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    query,\n",
    "    model,\n",
    "    preprocessors=[{\"lowercase\": True, \"strip_accents\": True}],\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we show how to report the corresponding p-value through a permutation test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male terms wrt Family terms and Career terms',\n",
       " 'result': 0.46343881433131173,\n",
       " 'weat': 0.46343881433131173,\n",
       " 'effect_size': 0.4507652792646716,\n",
       " 'p_value': 0.19068093190680932}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    query,\n",
    "    model,\n",
    "    calculate_p_value=True,\n",
    ")\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface allows us to easily switch to similar metrics (i.e., supporting the same number of number of word sets)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male terms wrt Family terms and Career terms',\n",
       " 'result': 0.09051558681296493,\n",
       " 'rnsb': 0.09051558681296493,\n",
       " 'negative_sentiment_probabilities': {'female': 0.5285811053851917,\n",
       "  'woman': 0.3031782770423851,\n",
       "  'girl': 0.20810547466232254,\n",
       "  'sister': 0.17327510211466302,\n",
       "  'she': 0.4165425516161486,\n",
       "  'her': 0.3895078245770702,\n",
       "  'hers': 0.31412920848479164,\n",
       "  'daughter': 0.13146512364633123,\n",
       "  'male': 0.42679205714649815,\n",
       "  'man': 0.43079499436045987,\n",
       "  'boy': 0.21701323144255624,\n",
       "  'brother': 0.19983034212661,\n",
       "  'he': 0.5645185337599223,\n",
       "  'him': 0.49470907399126185,\n",
       "  'his': 0.552712793795697,\n",
       "  'son': 0.17457869573293805},\n",
       " 'negative_sentiment_distribution': {'female': 0.09565807331470504,\n",
       "  'woman': 0.054866603359974946,\n",
       "  'girl': 0.03766114329405169,\n",
       "  'sister': 0.031357841309175544,\n",
       "  'she': 0.07538229712572722,\n",
       "  'her': 0.07048978417965314,\n",
       "  'hers': 0.05684840897525258,\n",
       "  'daughter': 0.02379143012863325,\n",
       "  'male': 0.07723716469755836,\n",
       "  'man': 0.0779615819300061,\n",
       "  'boy': 0.03927319268906782,\n",
       "  'brother': 0.036163580806998274,\n",
       "  'he': 0.10216172076480977,\n",
       "  'him': 0.0895282036894233,\n",
       "  'his': 0.10002521923736822,\n",
       "  'son': 0.03159375449759469}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wefe.metrics import RNSB\n",
    "\n",
    "rnsb = RNSB()\n",
    "result = rnsb.run_query(query, model)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_name': 'Female terms and Male terms wrt Family terms and Career terms',\n",
       " 'result': 0.8416415235615204,\n",
       " 'mac': 0.8416415235615204,\n",
       " 'targets_eval': {'Female terms': {'female': {'Family terms': 0.9185737599618733,\n",
       "    'Career terms': 0.916069650076679},\n",
       "   'woman': {'Family terms': 0.752434104681015,\n",
       "    'Career terms': 0.9377805145923048},\n",
       "   'girl': {'Family terms': 0.707457959651947,\n",
       "    'Career terms': 0.9867974997032434},\n",
       "   'sister': {'Family terms': 0.5973392464220524,\n",
       "    'Career terms': 0.9482253392925486},\n",
       "   'she': {'Family terms': 0.7872791914269328,\n",
       "    'Career terms': 0.9161583095556125},\n",
       "   'her': {'Family terms': 0.7883057091385126,\n",
       "    'Career terms': 0.9237247597193345},\n",
       "   'hers': {'Family terms': 0.7385367527604103,\n",
       "    'Career terms': 0.9480051446007565},\n",
       "   'daughter': {'Family terms': 0.5472579970955849,\n",
       "    'Career terms': 0.9277344475267455}},\n",
       "  'Male terms': {'male': {'Family terms': 0.8735092766582966,\n",
       "    'Career terms': 0.9468009045813233},\n",
       "   'man': {'Family terms': 0.8249392118304968,\n",
       "    'Career terms': 0.9350165261421353},\n",
       "   'boy': {'Family terms': 0.7106057899072766,\n",
       "    'Career terms': 0.9879048476286698},\n",
       "   'brother': {'Family terms': 0.6280269809067249,\n",
       "    'Career terms': 0.9477180293761194},\n",
       "   'he': {'Family terms': 0.8693044614046812,\n",
       "    'Career terms': 0.8771287016716087},\n",
       "   'him': {'Family terms': 0.8230192996561527,\n",
       "    'Career terms': 0.888683641096577},\n",
       "   'his': {'Family terms': 0.8876195731572807,\n",
       "    'Career terms': 0.8920885202242061},\n",
       "   'son': {'Family terms': 0.5764635019004345,\n",
       "    'Career terms': 0.9220191016211174}}}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from wefe.metrics import MAC\n",
    "\n",
    "mac = MAC()\n",
    "result = mac.run_query(query, model)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fair Embedding Engine\n",
    "\n",
    "In the case of Fair Embedding Engine, the WE model is passed in the metric instantiation.\n",
    "Then, the output value of the metric is computed using the `compute` method of the metric object.\n",
    "\n",
    "\n",
    "FEE differs somewhat from the WEFE standardization by making mandatory to provide the model when instantiating each metric, making the metric object model dependent.\n",
    "This makes it difficult to test several models at once since you have to instantiate a different metric object for each model.\n",
    "\n",
    "On the other hand, FEE does not establish a clear mechanism for passing sets of words of different sizes to the computation method: sets of words are delivered directly with a star parameter *, which defines an arbitrary number of positional arguments. This lack of definition makes it difficult for the user to understand how many and which word sets to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39821118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from FEE.fee.metrics import WEAT as FEE_WEAT\n",
    "\n",
    "fee_weat = FEE_WEAT(fee_model)\n",
    "\n",
    "fee_weat.compute(female_terms, male_terms, family_terms, career_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FEE implementation of WEAT also allows the calculation of the p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.39821118, 0.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fee_weat.compute(female_terms, male_terms, family_terms, career_terms, p_val=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the implementation of the metric does not support the execution of more complex actions, such as preprocessing word sets.\n",
    "We could not find any other metric that was easily replaceable using the same or a similar interface (with respect to the WEFE standardization layer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Responsibly\n",
    "\n",
    "Similar to WEFE, responsibly has a function that takes the model and word sets as input and returns the WEAT score as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key text.latex.unicode in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 112 ('text.latex.unicode : False # use \"ucs\" and \"inputenc\" LaTeX packages for handling')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key text.latex.preview in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 125 ('text.latex.preview : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key mathtext.fallback_to_cm in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 157 ('mathtext.fallback_to_cm : True  # When True, use symbols from the Computer Modern')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.jpeg_quality in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 420 ('savefig.jpeg_quality: 95       # when a jpeg is saved, the default quality parameter.')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key savefig.frameon in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 423 ('savefig.frameon : True')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key pgf.debug in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 444 ('pgf.debug           : False')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.level in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 475 ('verbose.level  : silent      # one of silent, helpful, debug, debug-annoying')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key verbose.fileo in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 476 ('verbose.fileo  : sys.stdout  # a log filename, sys.stdout or sys.stderr')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key keymap.all_axes in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 493 ('keymap.all_axes : a                 # enable all axes')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_path in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 504 ('animation.avconv_path: avconv     # Path to avconv binary. Without full path')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n",
      "\n",
      "Bad key animation.avconv_args in file /home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle, line 506 ('animation.avconv_args:            # Additional arguments to pass to avconv')\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.5.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Target words': 'female_terms vs. male_terms',\n",
       " 'Attrib. words': 'family_terms vs. career_terms',\n",
       " 's': 0.31658393144607544,\n",
       " 'd': 0.67794365,\n",
       " 'p': 0.09673659673659674,\n",
       " 'Nt': '8x2',\n",
       " 'Na': '8x2'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from responsibly.we.weat import calc_single_weat\n",
    "\n",
    "calc_single_weat(\n",
    "    twitter_25,\n",
    "    first_target={\"name\": \"female_terms\", \"words\": female_terms},\n",
    "    second_target={\"name\": \"male_terms\", \"words\": male_terms},\n",
    "    first_attribute={\"name\": \"family_terms\", \"words\": family_terms},\n",
    "    second_attribute={\"name\": \"career_terms\", \"words\": career_terms},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value can also be obtained from the same function by setting the `with_pvalue` parameter to `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Target words': 'female_terms vs. male_terms',\n",
       " 'Attrib. words': 'family_terms vs. career_terms',\n",
       " 's': 0.31658393144607544,\n",
       " 'd': 0.67794365,\n",
       " 'p': 0.09673659673659674,\n",
       " 'Nt': '8x2',\n",
       " 'Na': '8x2'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_single_weat(\n",
    "    twitter_25,\n",
    "    first_target={\"name\": \"female_terms\", \"words\": female_terms},\n",
    "    second_target={\"name\": \"male_terms\", \"words\": male_terms},\n",
    "    first_attribute={\"name\": \"family_terms\", \"words\": family_terms},\n",
    "    second_attribute={\"name\": \"career_terms\", \"words\": career_terms},\n",
    "    with_pvalue=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The implementation of this metric does not include the ability to perform more complex actions such as preprocessing word sets.\n",
    "\n",
    "In addition, we were unable to find any metrics in this library other than WEAT that are directly comparable to those implemented by WEFE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EmbeddingBiasScores\n",
    "\n",
    "EmbeddingBiasScores formalizes how bias is measured in a different way than WEFE: it classifies the methods into clustering or geometric methods (note that WEFE only implements the geometric equivalents).\n",
    "\n",
    "As part of their standardization, each geometric metric must first define the direction of the bias using the `define_bias_space` function with attribute_embeddings (attribute words) as input; and then use the `group_bias` or `mean_individual_bias` methods to compute the value of the metric.\n",
    "\n",
    "Examples of use are shown below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the embeddings to be used must be transformed by hand from words to arrays.\n",
    "target_embeddings = [\n",
    "    [model[word] for word in female_terms],\n",
    "    [model[word] for word in male_terms],\n",
    "]\n",
    "attribute_embeddings = [\n",
    "    [model[word] for word in family_terms],\n",
    "    [model[word] for word in career_terms],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4364516797305417"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EmbeddingBiasScores.geometrical_bias import WEAT\n",
    "\n",
    "weat = WEAT()\n",
    "weat.define_bias_space(attribute_embeddings)\n",
    "# group bias returns the effect size.\n",
    "weat.group_bias(target_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation of WEAT returns the effect size by default. There is no way to parameterize the metric to compute the WEAT score or the p-value.\n",
    "\n",
    "Similar to WEFE, the standardization implemented by EmbeddingBiasScores allows to easily change the used metric to another with the same input word sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8416415235615204"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EmbeddingBiasScores.geometrical_bias import MAC\n",
    "\n",
    "mac = MAC()\n",
    "mac.define_bias_space(attribute_embeddings)\n",
    "\n",
    "# mac does not accept more than one target set, so we have to calculate it manually.\n",
    "target_0_mac = mac.mean_individual_bias(target_embeddings[0])\n",
    "target_1_mac = mac.mean_individual_bias(target_embeddings[1])\n",
    "(target_0_mac + target_1_mac) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EmbeddingBiasScores includes metrics that WEFE does not yet implement, such as `GeneralizedWEAT` and `SAME`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02896493"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EmbeddingBiasScores.geometrical_bias import GeneralizedWEAT\n",
    "\n",
    "gweat = GeneralizedWEAT()\n",
    "gweat.define_bias_space(attribute_embeddings)\n",
    "gweat.group_bias(target_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2677120929221758"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from EmbeddingBiasScores.geometrical_bias import SAME\n",
    "\n",
    "same = SAME()\n",
    "same.define_bias_space(attribute_embeddings)\n",
    "same.mean_individual_bias(target_embeddings[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, EmbeddingBiasScores does not allow any of its metrics to perform more complex actions, such as preprocessing word set or customizing some performance settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In WEFE, having the input words as query objects decoupled from the execution of metrics allows both parameterization of metric execution and easy exchange of one metric for another. In addition, the clean and unified interface for all metrics makes the execution of bias measurements intuitive.\n",
    "\n",
    "\n",
    "Responsibly and FEE share a similar interface, in which the metric arguments are sets of words (which lack the expressiveness of WEFE queries to declare the number of sets of words supported by each metric), making it difficult to standardize inputs across metrics. We were unable to find any metrics other than WEAT to include in the benchmarking of FEE and Responsibly.\n",
    "\n",
    "\n",
    "On the other hand, EmbeddingBiasScores also presents its own mathematical standardization for each metric as well as some metrics that WEFE does not yet implement. \n",
    "While the standardization they present may be a bit more specific, it makes it more complex to use. \n",
    "\n",
    "The increased difficulty is mainly due to two factors: users have to manually define the bias space (using the `define_bias_space` parameter) and then investigate whether to use the parameters `group_bias` or `mean_individual_bias`, which is not clear at first sight unless the basics of the standardization proposed by this library have been previously studied.\n",
    "\n",
    "\n",
    "Finally, we highlight WEFE's `run_query` method, which allows the user to customize the execution of metrics, such as word preprocessing, normalization of embeddings, and calculation of submetrics or statistical tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "fee_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Ease of Running Bias Mitigation Algorithms\n",
    "\n",
    "Next we will compare how to run bias mitigation methods on the libraries included in the benchmark.\n",
    "In order to make the comparison as objective as possible, the set of words and the embedding model remain fixed; only the algorithms executed vary. Furthermore, to evaluate the performance of the implemented methods, we will use the same query defined in the previous section using WEAT (female vs. male terms with respect to family vs. career)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wefe.datasets import fetch_debiaswe\n",
    "from wefe.utils import load_test_model\n",
    "\n",
    "# word sets to be used\n",
    "debiaswe_wordsets = fetch_debiaswe()\n",
    "\n",
    "definitional_pairs = debiaswe_wordsets[\"definitional_pairs\"]\n",
    "gender_specific = debiaswe_wordsets[\"gender_specific\"]\n",
    "\n",
    "targets = [\n",
    "    \"executive\",\n",
    "    \"management\",\n",
    "    \"professional\",\n",
    "    \"corporation\",\n",
    "    \"salary\",\n",
    "    \"office\",\n",
    "    \"business\",\n",
    "    \"career\",\n",
    "    \"home\",\n",
    "    \"parents\",\n",
    "    \"children\",\n",
    "    \"family\",\n",
    "    \"cousins\",\n",
    "    \"marriage\",\n",
    "    \"wedding\",\n",
    "    \"relatives\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. WEFE\n",
    "\n",
    "WEFE defines a standardized framework for executing bias mitigation algorithms based on the scikit-learn fit transform interface. \n",
    "\n",
    "The fit-transform interface allows the user to select the sets of words and parameters that will be used to learn the debiasing transformation (`fit`), as well as to select the words that will be effectively debiased by the method (`transform`).\n",
    "\n",
    "\n",
    "This allows the user to change the words used to define the bias criterion (which is usually gender, but could be easily changed), as well as the vocabulary word to which the mitigation is applied. This software design pattern is useful for comparing different de-biasing methods, as the user can ensure that the same parameters are used across methods.\n",
    "\n",
    "\n",
    "Below we show how to execute a mitigation method with WEFE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "/home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy argument is True. Transform will attempt to create a copy of the original model. This may fail due to lack of memory.\n",
      "Model copy created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 21809.84it/s]\n"
     ]
    }
   ],
   "source": [
    "from wefe.debias.hard_debias import HardDebias\n",
    "from wefe.debias.hard_debias import HardDebias\n",
    "from wefe.word_embedding_model import WordEmbeddingModel\n",
    "from gensim import downloader as api\n",
    "\n",
    "# load glove model\n",
    "twitter_25 = api.load(\"glove-twitter-25\")\n",
    "model = WordEmbeddingModel(twitter_25, \"glove twitter dim=25\")\n",
    "\n",
    "# 1. instance Hard Debias algortihm\n",
    "hd = HardDebias(\n",
    "    verbose=False,\n",
    "    criterion_name=\"gender\",\n",
    ")\n",
    "\n",
    "# 2. apply fit method and pass the model and definitional pairs.\n",
    "hd.fit(model, definitional_pairs=definitional_pairs)\n",
    "\n",
    "# 3. apply transform method passing the model, target and ignore word sets resulting in the debiased model\n",
    "hd_debiased_model = hd.transform(\n",
    "    model,\n",
    "    target=targets,\n",
    "    ignore=gender_specific,\n",
    "    copy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we show how to change the debiasing method while keeping a very similar parameter configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3373: RuntimeWarning: Mean of empty slice.\n",
      "/home/pablo/miniconda3/envs/wefe/lib/python3.7/site-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy argument is True. Transform will attempt to create a copyof the original model. This may fail due to lack of memory.\n",
      "Model copy created successfully.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 16/16 [00:03<00:00,  5.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 16/16 [00:00<00:00, 45964.98it/s]\n"
     ]
    }
   ],
   "source": [
    "from wefe.debias.repulsion_attraction_neutralization import (\n",
    "    RepulsionAttractionNeutralization,\n",
    ")\n",
    "\n",
    "ran = RepulsionAttractionNeutralization().fit(\n",
    "    model=model,\n",
    "    definitional_pairs=definitional_pairs,\n",
    ")\n",
    "\n",
    "ran_debiased_model = ran.transform(\n",
    "    model=model,\n",
    "    target=targets,\n",
    "    ignore=gender_specific,\n",
    "    copy=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the fit-transform standardization implemented in WEFE allows to easily execute and exchange the different bias mitigation methods implemented in the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model WEAT evaluation:  0.31658415612764657\n",
      "Hard Debias debiased model WEAT evaluation:  0.002320525236427784\n",
      "Repulsion Attraction Neutralization debiased model WEAT evaluation:  0.26007230998948216\n"
     ]
    }
   ],
   "source": [
    "from wefe.metrics import WEAT\n",
    "\n",
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    query,\n",
    "    model,\n",
    ")\n",
    "print(\"Original model WEAT evaluation: \", result[\"weat\"])\n",
    "\n",
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    query,\n",
    "    hd_debiased_model,\n",
    ")\n",
    "print(\"Hard Debias debiased model WEAT evaluation: \", result[\"weat\"])\n",
    "\n",
    "\n",
    "weat = WEAT()\n",
    "result = weat.run_query(\n",
    "    query,\n",
    "    ran_debiased_model,\n",
    ")\n",
    "print(\n",
    "    \"Repulsion Attraction Neutralization debiased model WEAT evaluation: \",\n",
    "    result[\"weat\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "hd_debiased_model=None\n",
    "ran_debiased_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fair Embedding Engine\n",
    "\n",
    "The Fair Embedding Engine (FEE) requires the embedding model to be passed during instantiation of the algorithm. It currently does not support user-given  definitional pairs, as the word sets used are fixed in this implementation, focusing only on gender bias at the moment.\n",
    "\n",
    "\n",
    "Debiasing is performed by executing the run method. The list of target words to be debiased must be provided in this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from FEE.fee.embedding.loader import WE\n",
    "\n",
    "# load model\n",
    "fee_model = WE().load(ename=\"glove-twitter-25\")\n",
    "# model must be normalized\n",
    "fee_model.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FEE.fee.debias import HardDebias\n",
    "\n",
    "# instance the algortihm and apply it to the embedding model\n",
    "fee_hd_debiased_model = HardDebias(copy.deepcopy(fee_model)).run(word_list=targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEE allows easy use of different debiasing methods with a similar interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo/Proyectos/WEFE/wefe/FEE/fee/debias/ran_debias.py:127: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  ../torch/csrc/utils/tensor_new.cpp:204.)\n"
     ]
    }
   ],
   "source": [
    "from FEE.fee.debias import RANDebias\n",
    "\n",
    "# instance the algortihm and apply it to the embedding model\n",
    "ran_hd_debiased_model = RANDebias(copy.deepcopy(fee_model)).run(words=targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model WEAT evaluation:  0.31658416730351746\n",
      "Hard Debias debiased model WEAT evaluation:  -0.061893132515251637\n",
      "Repulsion Attraction Neutralization debiased model WEAT evaluation:  0.17548414319753647\n"
     ]
    }
   ],
   "source": [
    "# in the case, we generate a custom weat calculation using the fee debiasing methods.\n",
    "result = WEAT()._calc_weat(\n",
    "    [fee_model.v(word) for word in query.target_sets[0]],\n",
    "    [fee_model.v(word) for word in query.target_sets[1]],\n",
    "    [fee_model.v(word) for word in query.attribute_sets[0]],\n",
    "    [fee_model.v(word) for word in query.attribute_sets[1]],\n",
    ")\n",
    "\n",
    "print(\"Original model WEAT evaluation: \", result)\n",
    "result = WEAT()._calc_weat(\n",
    "    [fee_hd_debiased_model.v(word) for word in query.target_sets[0]],\n",
    "    [fee_hd_debiased_model.v(word) for word in query.target_sets[1]],\n",
    "    [fee_hd_debiased_model.v(word) for word in query.attribute_sets[0]],\n",
    "    [fee_hd_debiased_model.v(word) for word in query.attribute_sets[1]],\n",
    ")\n",
    "print(\"Hard Debias debiased model WEAT evaluation: \", result)\n",
    "result = WEAT()._calc_weat(\n",
    "    [ran_hd_debiased_model.v(word) for word in query.target_sets[0]],\n",
    "    [ran_hd_debiased_model.v(word) for word in query.target_sets[1]],\n",
    "    [ran_hd_debiased_model.v(word) for word in query.attribute_sets[0]],\n",
    "    [ran_hd_debiased_model.v(word) for word in query.attribute_sets[1]],\n",
    ")\n",
    "print(\"Repulsion Attraction Neutralization debiased model WEAT evaluation: \", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free memory\n",
    "ran_hd_debiased_model = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Responsibly\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Responsibly the embedding model is provided during the instantiation of the `GenderBiasWe` class. Definitional pairs cannot be provided by the user, as the bias being mitigated is set specifically to gender bias. \n",
    "To perform the debiasing process, one simply needs to execute the `debias` method.\n",
    "\n",
    "However, it should be noted that the mitigation method cannot be run on the benchmark model chosen, as it is not compatible with uncased models such as `twitter-25`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from responsibly.we import GenderBiasWE\n",
    "\n",
    "# does not work with twitter_25. \n",
    "gender_bias_we = GenderBiasWE(word2vec)  # instance the GenderBiasWE\n",
    "gender_bias_we.debias(neutral_words=targets)  # apply the debias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EmbeddingBiasScore\n",
    "\n",
    "The library does not implement mitigation methods, so it is not included in this comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "\n",
    "All three libraries offer a simple way to apply bias mitigation algorithms in a similar way and all of them are able to mitigate bias in the word embedding model by similar amounts, depending on the metric used.\n",
    "\n",
    "The main difference between them is that WEFE offers more flexibility to users, allowing them to choose the bias criteria through the words used to learn the transformation and the words that are mitigated. On the other hand, FEE and Responsibly only work with gender bias because the set of words is fixed by default.\n",
    "\n",
    "Finally, WEFE includes more mitigation algorithms than the other two frameworks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Metrics and Mitigation Methods Implemented\n",
    "\n",
    "The following tables provide a comparison of the libraries included in this benchmarking, with respect to the bias metrics and mitigation methods they implement to date.\n",
    "\n",
    "### Fairness Metrics\n",
    "\n",
    "| Metric           | WEFE | FEE | Responsibly | EmbeddingBiasScores |\n",
    "| ---------------- | ---- | --- | ----------- | ------------------- |\n",
    "| WEAT             | ✔    | ✔   | ✔           | ✔                   |\n",
    "| WEAT ES          | ✔    | ✖   | ✖           | ✖                   |\n",
    "| RNSB             | ✔    | ✖   | ✖           | ✖                   |\n",
    "| RIPA             | ✔    | ✖   | ✖           | ✔                   |\n",
    "| ECT              | ✔    | ✖   | ✖           | ✖                   |\n",
    "| RND              | ✔    | ✖   | ✖           | ✖                   |\n",
    "| MAC              | ✔    | ✖   | ✖           | ✔                   |\n",
    "| Direct Bias      | ✖    | ✔   | ✔           | ✔                   |\n",
    "| SAME             | ✖    | ✖   | ✖           | ✔                   |\n",
    "| Generalized WEAT | ✖    | ✖   | ✖           | ✔                   |\n",
    "\n",
    "The table exclusively focuses on metrics that directly compute from word embeddings\n",
    "(WE) using predefined word sets. As a result, it omits the following metrics:\n",
    "\n",
    "- IndirectBias, a metric that accepts as input only two words and the gender\n",
    "  direction, previously calculated in a distinct operation.\n",
    "- GIPE, PMN, and Proximity Bias, which evaluate WE models before and after debiasing\n",
    "  with auxiliary mitigation methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Mitigation algorithms\n",
    "\n",
    "| Algorithm               | WEFE | FEE | Responsibly | EmbeddingBiasScores |\n",
    "|-------------------------|------|-----|-------------|---------------------|\n",
    "| Hard Debias             | ✔    | ✔   | ✔           | ✖                   |\n",
    "| Double Hard Debias      | ✔    | ✖   | ✖           | ✖                   |\n",
    "| Half Sibling Regression | ✔    | ✔   | ✖           | ✖                   |\n",
    "| RAN                     | ✔    | ✔   | ✖           | ✖                   |\n",
    "| Multiclass HD           | ✔    | ✖   | ✖           | ✖                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The following table summarizes the main differences between the libraries analyzed in this benchmark study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|                                                | WEFE                                    | FEE                                                                  | Responsibly                               | EmbeddingBiasScores                |\n",
    "|------------------------------------------------|-----------------------------------------|----------------------------------------------------------------------|-------------------------------------------|------------------------------------|\n",
    "| Implemented   Metrics                          | 7                                       | 7                                                                    | 3                                         |                                  6 |\n",
    "| Implemented   Mitigation Algorithms                | 5                                       | 3                                                                    | 1                                         |                                  0 |\n",
    "| Extensible                                     | Easy                                    | Easy                                                                 | Difficult,   not very modular.            | Easy                               |\n",
    "| Well-defined   interface for metrics           | ✔                                       | ✖                                                                    | ✖                                         | ✔                                  |\n",
    "| Well-defined   interface for mitigation algorithms | ✔                                       | ✖                                                                    | ✖                                         | ✖                                  |\n",
    "| Lastest update                               | January 2023                                 | October 2020                                                             | April 2021                                  | April 2023                            |\n",
    "| Installation                                        | Easy:   pip or conda                    | No instructions. It can be installed from the repository | Only   with pip. Presents problems        | Only   from the repository         |\n",
    "| Documentation                                  | Extensive   documentation with examples | Almost   no documentation                                            |  Limited documentation with some examples | No   documentation, only examples. |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differences between IJCAI version and Current version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most noticeable change we can mention with respect to the IJCAI version and the current version is the full implementation of a new debiasing methods module. It includes 5 methods of debiasing: `HardDebias`, `MulticlassHardDebias`, `DoubleHardDebias`, `RepulsionAttractionNeutralization` and `HalfSiblingRegression`.\n",
    "\n",
    "Regarding metrics: The original version of WEFE published in IJCAI contained 4 metrics: `WEAT`, `WEAT-ES`, `RND` and `RNSB`.\n",
    "Currently and thanks to contributions, WEFE also implements `MAC`, `RIPA` and `ECT`.\n",
    "\n",
    "Also, the original version contained very rudimentary `Query` and `WordEmbeddingModel` wrapper routines.\n",
    "\n",
    "In the actual version, the wrappers are much more complete and allow better interaction  with the user and with WEFE's internal APIs.  \n",
    "\n",
    "\n",
    "For example, the implementation of `__repr__` for `Query` and `WordEmbeddingModel` contain short descriptions of each object for the user. We have also included a `dict` method in `Query` that allows to transform a query into a dictionary and the `update` in `WordEmbeddingModel` that allows to update an embedding associated to a word by a new one.\n",
    "\n",
    "\n",
    "The `preprocessing` module has also been improved to cover a wider range of operations (such as different preprocessing steps) that have been modularized and generalized so that any metric or mitigation method can use it.\n",
    "\n",
    "The documentation has been significantly improved from the original release. These improvements include the addition of new user guides, conceptual guides explaining the theoretical framework, multi-language tutorials, and detailed API documentation covering metrics and mitigation methods, including theoretical details. It is also worth noting that there have been notable improvements in both testing and code quality compared to the original release."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "37d01894bb315c73bf6fde5551d8a97078996f38b23395695bd1998fb0ae5507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
